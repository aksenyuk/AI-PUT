{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NAb1_oTJHLYJ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "371N6-Dw9z_y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "57nuLydYJESc"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6_wPPft7nOP",
        "outputId": "0e6f4523-f52d-4bf7-8ce8-ac6afd13ddd3"
      },
      "outputs": [],
      "source": [
        "!wget \"https://chmura.put.poznan.pl/s/LxYSsota5PCbXcU/download\" -O dataset.zip\n",
        "!unzip -q dataset.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rWEgmvmEfAR8"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezCx90V9fMps"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# import os\n",
        "# import pandas as pd\n",
        "# import shutil\n",
        "\n",
        "# source_folder = \"./dataset\"\n",
        "# output_folder = \"./combined_dataset/images\"\n",
        "\n",
        "# if not os.path.exists(output_folder):\n",
        "#     os.makedirs(output_folder)\n",
        "\n",
        "# counter = 0\n",
        "\n",
        "# combined_data = pd.DataFrame(columns=[\"image\", \"forward\", \"left\"])\n",
        "\n",
        "# csv_files = [file for file in os.listdir(source_folder) if file.endswith(\".csv\")]\n",
        "# for csv_file in csv_files:\n",
        "#     csv_file_path = os.path.join(source_folder, csv_file)\n",
        "\n",
        "#     data = pd.read_csv(csv_file_path, names=[\"image\", \"forward\", \"left\"])\n",
        "\n",
        "#     folder_name = os.path.splitext(csv_file)[0]\n",
        "\n",
        "#     for _, row in data.iterrows():\n",
        "#         image_name = f\"{int(row['image']):04d}.jpg\"\n",
        "#         old_image_path = os.path.join(source_folder, folder_name, image_name)\n",
        "#         new_image_name = f\"{counter:04d}.jpg\"\n",
        "#         new_image_path = os.path.join(output_folder, new_image_name)\n",
        "\n",
        "#         shutil.copy2(old_image_path, new_image_path)\n",
        "\n",
        "#         combined_data = combined_data.append({\"image\": new_image_name, \"forward\": row['forward'], \"left\": row['left']},\n",
        "#                                              ignore_index=True)\n",
        "#         counter += 1\n",
        "\n",
        "# combined_data.to_csv(\"./combined_dataset/targets.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5iFbKN4Xb8U"
      },
      "outputs": [],
      "source": [
        "def expandImagePath(img_dir_path, short_name):\n",
        "    return os.path.join(img_dir_path, str(short_name).zfill(4) + '.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSsgv1hlHfBf"
      },
      "outputs": [],
      "source": [
        "shift_sizes = list(range(4))\n",
        "output_csv_prefix = \"./annotations\"\n",
        "\n",
        "output_files = {output_csv_prefix + f\"_{shift_size}.csv\": shift_size for shift_size in shift_sizes}\n",
        "\n",
        "dataset_path = \"./dataset\"\n",
        "\n",
        "for output_csv_path, shift_size in output_files.items():\n",
        "    col_names = ['img_name', 'forward', 'left']\n",
        "    annotations = pd.DataFrame(columns = col_names)\n",
        "\n",
        "    for csv_path in sorted(glob.glob(os.path.join(dataset_path, '*.csv'))):\n",
        "        img_dir_path = csv_path.split('.csv')[0]\n",
        "        df = pd.read_csv(csv_path, names = col_names)\n",
        "        # Shift data\n",
        "        df['forward'] = df['forward'].shift(-shift_size)\n",
        "        df['left'] = df['left'].shift(-shift_size)\n",
        "        # Remove last rows whithout shifted data\n",
        "        df = df.drop(df.tail(shift_size).index)\n",
        "        # Transform image name into full path\n",
        "        df['img_name'] = df['img_name'].apply(lambda name: expandImagePath(img_dir_path, name))\n",
        "        # Combine to a single DF\n",
        "        annotations = pd.concat([annotations, df], axis=0, sort=False)\n",
        "    # Save to a file\n",
        "    annotations.to_csv(output_csv_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "J7QyI0ToSn4e",
        "outputId": "bf1d2e35-b64c-41fb-fd3a-9ced75e5fbff"
      },
      "outputs": [],
      "source": [
        "output_csv_path = \"./annotations_0.csv\"\n",
        "\n",
        "annotations = pd.read_csv(output_csv_path)\n",
        "annotations.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r8lOskW8fEgG"
      },
      "source": [
        "## Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELdGdesfChJE"
      },
      "outputs": [],
      "source": [
        "class DrivingDataset(Dataset):\n",
        "    def __init__(self, csv_path, transform=None):\n",
        "        self.annotations = pd.read_csv(csv_path)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # x\n",
        "        img_path = self.annotations.iloc[index, 0]\n",
        "        image = cv2.imread(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        # y\n",
        "        activations =  torch.tensor(self.annotations.iloc[index, 1:], dtype=torch.float32)\n",
        "        return image, activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltoIEnPMcrfB"
      },
      "outputs": [],
      "source": [
        "### AUGMENTATION IS ALSO APPLIED TO VALIDATION, TO AVOID IT, SPLIT DATA BEFORE CREATING DATASET AND CREATE TWO SEPARATE DATASETS\n",
        "\n",
        "# transform = A.Compose([\n",
        "#     A.Resize(224, 224),\n",
        "#     A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.5),\n",
        "#     A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.5),\n",
        "#     A.GaussNoise(p=0.5),\n",
        "#     A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.6), p=0.5),\n",
        "#     A.MotionBlur(p=0.2),\n",
        "#     A.Normalize(mean=[125.6922, 105.8604, 116.4662], std=[50.3127, 43.3011, 45.1162]),\n",
        "#     ToTensorV2(),\n",
        "# ])\n",
        "\n",
        "\n",
        "transform = torchvision.transforms.ToTensor()\n",
        "\n",
        "\n",
        "def getDataLoaders(output_csv_path, train_size, BATCH_SIZE):\n",
        "    dataset = DrivingDataset(output_csv_path, transform) \n",
        "\n",
        "    n_examples_train = int(len(dataset) * train_size)\n",
        "    n_examples_test = len(dataset) - n_examples_train\n",
        "\n",
        "    train_set, test_set = torch.utils.data.random_split(dataset, [n_examples_train, n_examples_test])\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_set, batch_size = BATCH_SIZE, shuffle = True)\n",
        "    test_loader = DataLoader(dataset = test_set, batch_size = BATCH_SIZE, shuffle = False)\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GpZVR5h4ou6w"
      },
      "source": [
        "### Preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0za74YffjMb"
      },
      "outputs": [],
      "source": [
        "output_csv_path = \"./annotations_0.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "K54Wl-Z9mnWZ",
        "outputId": "48fdd59b-8920-4f41-bdd5-bad38c733c09"
      },
      "outputs": [],
      "source": [
        "train_size = 1\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader, test_loader = getDataLoaders(output_csv_path, train_size, BATCH_SIZE)\n",
        "\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "\n",
        "print(f\"x batch shape: {train_features.size()}\")\n",
        "print(f\"y batch shape: {train_labels.size()}\")\n",
        "\n",
        "img = train_features[0].squeeze().permute(1, 2, 0)\n",
        "label = train_labels[0]\n",
        "\n",
        "plt.axis('off')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9cnNK_kfJIIm"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdy3vKgwJJ-g"
      },
      "outputs": [],
      "source": [
        "class DrivingModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(8 * 56 * 56, 32)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 8 * 56 * 56)\n",
        "        x = self.relu3(self.fc(x))\n",
        "        x = self.tanh(self.fc2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmoCQlleqJBy"
      },
      "outputs": [],
      "source": [
        "class AdaptiveAvgPool2dCustom(nn.Module):\n",
        "    def __init__(self, output_size):\n",
        "        super(AdaptiveAvgPool2dCustom, self).__init__()\n",
        "        self.output_size = np.array(output_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        stride_size = np.floor(np.array(x.shape[-2:]) / self.output_size).astype(np.int32)\n",
        "        kernel_size = np.array(x.shape[-2:]) - (self.output_size - 1) * stride_size\n",
        "        avg = nn.AvgPool2d(kernel_size=list(kernel_size), stride=list(stride_size))\n",
        "        x = avg(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWvLR3VuFYY6",
        "outputId": "32d19c0d-e909-4bc2-a5ac-da515c04a7ea"
      },
      "outputs": [],
      "source": [
        "class DeepConvModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(32, 32, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(64, 64, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(128, 128, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            AdaptiveAvgPool2dCustom((10, 10))\n",
        "            # nn.AdaptiveAvgPool2d((10, 10))\n",
        "\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(12800, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(32, 2),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "model = DeepConvModel()\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32TN4fVPGrmH",
        "outputId": "0e5046ce-ef4b-4e60-943b-9688aa9f40e0"
      },
      "outputs": [],
      "source": [
        "class DeepConvModel2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(3, 8, kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(8, 8, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv2d(8, 12, kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(12, 12, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(12*56*56, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(16, 2),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "model = DeepConvModel2()\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE0umCumHv-E",
        "outputId": "8f4e3095-ecf1-429c-a6be-12071f2be6ca"
      },
      "outputs": [],
      "source": [
        "class DeepConvModel3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(16, 16, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(32, 32, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv2d(64, 64, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d((10, 10))\n",
        "\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(9216, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(64, 2),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "model = DeepConvModel3()\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e0Mp9sfiXcp",
        "outputId": "25cca2eb-520a-453a-c9d1-16d046c468db"
      },
      "outputs": [],
      "source": [
        "# models = {\"DrivingModel\": DrivingModel()}\n",
        "\n",
        "# for modelName, model in models.items():\n",
        "#     n_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "#     print(f\"{modelName} Number of trainable parameters: {n_trainable_params}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o5fiXZfB1vlD"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkMCjpVAffmm"
      },
      "outputs": [],
      "source": [
        "def train_step(model, inputs, targets, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def val_step(model, inputs, targets, criterion):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "# class Checkpoint:\n",
        "#     def __init__(self, checkpoint_path = \"./model.pt\"):\n",
        "#         self.checkpoint_path = checkpoint_path\n",
        "#         self.min_monitor_loss = np.inf\n",
        "\n",
        "#     def checkpoint(self, monitor_loss):\n",
        "#         if monitor_loss < self.min_monitor_loss:\n",
        "#             self.min_monitor_loss = monitor_loss\n",
        "#             torch.save(model.state_dict(), self.checkpoint_path)\n",
        "#             print(f\"\\tSaved checkpoint at {self.checkpoint_path}\")\n",
        "\n",
        "\n",
        "# class EarlyStopper:\n",
        "#     def __init__(self, patience=1, min_delta=0):\n",
        "#         self.patience = patience\n",
        "#         self.min_delta = min_delta\n",
        "#         self.counter = 0\n",
        "#         self.min_monitor_loss = np.inf\n",
        "\n",
        "#     def stop(self, monitor_loss):\n",
        "#         if monitor_loss < self.min_monitor_loss:\n",
        "#             self.min_monitor_loss = monitor_loss\n",
        "#             self.counter = 0\n",
        "#         elif monitor_loss > (self.min_monitor_loss + self.min_delta):\n",
        "#             self.counter += 1\n",
        "#             if self.counter >= self.patience:\n",
        "#                 return True\n",
        "#         return False\n",
        "\n",
        "\n",
        "def train_loop(model, checkpoint_path, N_EPOCHS, train_loader, val_loader):\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Using device:\", DEVICE)\n",
        "    device = torch.device(DEVICE)\n",
        "    # model.to(device)\n",
        "\n",
        "    criterion_mse = nn.MSELoss().to(device)\n",
        "    criterion_mae = nn.L1Loss().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=0.1, verbose=True)\n",
        "\n",
        "    # checkpoint = Checkpoint(checkpoint_path)\n",
        "    # early = EarlyStopper(patience=3)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_losses_mae = []\n",
        "    n_batches_train = len(train_loader)\n",
        "    n_batches_val = len(val_loader)\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        total_epoch_loss_train = 0.0\n",
        "        total_epoch_loss_val = 0.0\n",
        "        total_epoch_loss_val_mae = 0.0\n",
        "        # Training\n",
        "        for i, data in enumerate(train_loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            total_epoch_loss_train += train_step(model, inputs, labels, optimizer, criterion_mse)\n",
        "\n",
        "        if epoch in (20, 30):\n",
        "            scheduler.step()\n",
        "\n",
        "        # Validation\n",
        "        for i, data in enumerate(val_loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            total_epoch_loss_val += val_step(model, inputs, labels, criterion_mse)\n",
        "            total_epoch_loss_val_mae += val_step(model, inputs, labels, criterion_mae)\n",
        "        # Storing losses\n",
        "        avg_epoch_loss_train = total_epoch_loss_train / n_batches_train\n",
        "        train_losses.append(avg_epoch_loss_train)\n",
        "        avg_epoch_loss_val = total_epoch_loss_val / n_batches_val\n",
        "        val_losses.append(avg_epoch_loss_train)\n",
        "        avg_epoch_loss_val_mae = total_epoch_loss_val_mae / n_batches_val\n",
        "        val_losses_mae.append(avg_epoch_loss_val_mae)\n",
        "        print(f\"Epoch [{epoch + 1}/{N_EPOCHS}], Loss: {avg_epoch_loss_train:.4f}, Validation loss: {avg_epoch_loss_val:.4f}, Validation loss MAE: {avg_epoch_loss_val_mae:.4f}\")\n",
        "        # Checkpoint\n",
        "        # checkpoint.checkpoint(avg_epoch_loss_val)\n",
        "        # Early stopping\n",
        "        # if early.stop(avg_epoch_loss_val):\n",
        "        #     print(\"\\tEarly stopping\")\n",
        "        #     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gasqg_RuFcb2",
        "outputId": "391c2d9c-55f2-4996-aec7-c5ea1703b3a0"
      },
      "outputs": [],
      "source": [
        "train_loader, test_loader = getDataLoaders(output_csv_path, 1, BATCH_SIZE)\n",
        "N_EPOCHS = 40\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(DEVICE)\n",
        "\n",
        "model = DeepConvModel2().to(device)\n",
        "\n",
        "train_loop(model, None, N_EPOCHS, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "train_features, train_labels = next(iter(test_loader))\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    img = train_features[i].to(device).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(img).cpu().numpy()[0]\n",
        "\n",
        "    image = img.squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "    y_true = train_labels[i].numpy()\n",
        "\n",
        "    y = np.array([y_true, y_pred])\n",
        "\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(str(y), fontsize = 10)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "torch.onnx.export(model,\n",
        "                    dummy_input,\n",
        "                    './model2.onnx',\n",
        "                    export_params=True,\n",
        "                    opset_version=11,\n",
        "                    do_constant_folding=True,\n",
        "                    input_names = ['input'],\n",
        "                    output_names = ['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l91SBp5rzHGi",
        "outputId": "e26b26a5-009f-468e-de8e-5a7daec33391"
      },
      "outputs": [],
      "source": [
        "# N_EPOCHS = 30\n",
        "\n",
        "# output_files = {output_csv_prefix + f\"_{shift_size}.csv\": shift_size for shift_size in shift_sizes}\n",
        "# models = {output_csv_path: [f\"DrivingModel_shift_{shift_size}\", DrivingModel()]\n",
        "#           for output_csv_path, shift_size in output_files.items()}\n",
        "\n",
        "# for output_csv_path, modelWithName in models.items():\n",
        "#     modelName, model = modelWithName\n",
        "#     checkpoint_path = f\"./{modelName}.pt\"\n",
        "\n",
        "#     train_loader, test_loader = getDataLoaders(output_csv_path, train_size, BATCH_SIZE)\n",
        "\n",
        "#     print(modelName)\n",
        "#     train_loop(model, checkpoint_path, N_EPOCHS, train_loader, test_loader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "muarRLxMble7"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BakLimB0wcZi"
      },
      "outputs": [],
      "source": [
        "# def test_loop(model, checkpoint_path, test_loader):\n",
        "#     DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#     print(\"Using device:\", DEVICE)\n",
        "#     device = torch.device(DEVICE)\n",
        "\n",
        "#     criterion = nn.MSELoss().to(device)\n",
        "#     criterion_mae = nn.L1Loss().to(device)\n",
        "\n",
        "#     n_batches = len(test_loader)\n",
        "\n",
        "#     # model.load_state_dict(torch.load(checkpoint_path))\n",
        "#     model.to(device)\n",
        "#     model.eval()\n",
        "\n",
        "#     total_loss = 0.0\n",
        "#     total_loss_mae = 0.0\n",
        "#     for i, data in enumerate(test_loader):\n",
        "#         inputs, labels = data\n",
        "#         inputs, labels = inputs.to(device), labels.to(device)\n",
        "#         total_loss += val_step(model, inputs, labels, criterion)\n",
        "#         total_loss_mae += val_step(model, inputs, labels, criterion_mae)\n",
        "#     avg_loss = total_loss / n_batches\n",
        "#     avg_loss_mae = total_loss_mae / n_batches\n",
        "#     print(f\"\\tValidation loss: {avg_loss:.4f}, Validation loss MAE: {avg_loss_mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpU_kaj9WSoJ",
        "outputId": "cb1bdc64-3452-435f-a1ff-e20872210dc4"
      },
      "outputs": [],
      "source": [
        "# output_files = {output_csv_prefix + f\"_{shift_size}.csv\": shift_size for shift_size in shift_sizes}\n",
        "# models = {output_csv_path: [f\"DrivingModel_shift_{shift_size}\", DrivingModel()]\n",
        "#           for output_csv_path, shift_size in output_files.items()}\n",
        "\n",
        "# for output_csv_path, modelWithName in models.items():\n",
        "#     modelName, model = modelWithName\n",
        "#     checkpoint_path = f\"./{modelName}.pt\"\n",
        "\n",
        "#     train_loader, test_loader = getDataLoaders(output_csv_path, train_size, BATCH_SIZE)\n",
        "\n",
        "#     print(modelName)\n",
        "#     test_loop(model, checkpoint_path, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "UsDfo6xgaqDB",
        "outputId": "9c851d42-8d8a-4b44-93e7-36ff3f2b92cd"
      },
      "outputs": [],
      "source": [
        "# model.eval()\n",
        "# train_features, train_labels = next(iter(test_loader))\n",
        "# figure = plt.figure(figsize=(8, 8))\n",
        "# cols, rows = 3, 3\n",
        "# for i in range(1, cols * rows + 1):\n",
        "#     img = train_features[i].to(device).unsqueeze(0)\n",
        "#     # print(img.shape)\n",
        "#     with torch.no_grad():\n",
        "#         y_pred = model(img).cpu().numpy()[0]\n",
        "\n",
        "#     image = img.squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "#     y_true = train_labels[i].numpy()\n",
        "\n",
        "#     y = np.array([y_true, y_pred])\n",
        "\n",
        "#     figure.add_subplot(rows, cols, i)\n",
        "#     plt.title(str(y), fontsize = 10)\n",
        "#     plt.axis(\"off\")\n",
        "#     plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-70DQ30RoxT5",
        "outputId": "4bde8328-008b-4424-cdd5-d3b85c36f20f"
      },
      "outputs": [],
      "source": [
        "# dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "# torch.onnx.export(model,\n",
        "#                     dummy_input,\n",
        "#                     './model.onnx',\n",
        "#                     export_params=True,\n",
        "#                     opset_version=11,\n",
        "#                     do_constant_folding=True,\n",
        "#                     input_names = ['input'],\n",
        "#                     output_names = ['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "6oSX3d5eipBz",
        "outputId": "7a90e613-0952-42c3-fef5-2ee561f307aa"
      },
      "outputs": [],
      "source": [
        "# output_files = {output_csv_prefix + f\"_{shift_size}.csv\": shift_size for shift_size in shift_sizes}\n",
        "# models = {output_csv_path: [f\"DrivingModel_shift_{shift_size}\", DrivingModel()]\n",
        "#           for output_csv_path, shift_size in output_files.items()}\n",
        "\n",
        "# train_size = 0.9\n",
        "# BATCH_SIZE = 32\n",
        "\n",
        "# output_csv_path = \"./annotations_0.csv\"\n",
        "# _, test_loader = getDataLoaders(output_csv_path, train_size, BATCH_SIZE)\n",
        "# train_features, train_labels = next(iter(test_loader))\n",
        "\n",
        "# for _, modelWithName in models.items():\n",
        "#     modelName, model = modelWithName\n",
        "#     checkpoint_path = f\"./{modelName}.pt\"\n",
        "#     model.load_state_dict(torch.load(checkpoint_path))\n",
        "#     model.eval()\n",
        "\n",
        "#     figure = plt.figure(figsize=(8, 8))\n",
        "#     cols, rows = 3, 3\n",
        "#     for i in range(1, cols * rows + 1):\n",
        "#         img = train_features[i]\n",
        "#         with torch.no_grad():\n",
        "#             y_pred = model(img).numpy()[0]\n",
        "\n",
        "#         image = img.squeeze().permute(1, 2, 0).numpy()\n",
        "#         y_true = train_labels[i].numpy()\n",
        "\n",
        "#         y = np.array([y_true, y_pred])\n",
        "\n",
        "#         figure.add_subplot(rows, cols, i)\n",
        "#         plt.title(str(y), fontsize = 10)\n",
        "#         plt.axis(\"off\")\n",
        "#         plt.imshow(image)\n",
        "#     figure.suptitle(modelName)\n",
        "#     plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VmGuYKjUmvZB"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tCK_vBx636S",
        "outputId": "48bdfdd4-bf20-4745-b91d-b0e60e1d4cb8"
      },
      "outputs": [],
      "source": [
        "# !pip3 install onnx\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV4UDeQrmz7r",
        "outputId": "4ed3f088-89d4-4f57-9a16-2fbe760db966"
      },
      "outputs": [],
      "source": [
        "# output_files = {output_csv_prefix + f\"_{shift_size}.csv\": shift_size for shift_size in shift_sizes}\n",
        "# models = {output_csv_path: [f\"DrivingModel_shift_{shift_size}\", DrivingModel()]\n",
        "#           for output_csv_path, shift_size in output_files.items()}\n",
        "\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# print(\"Using device:\", DEVICE)\n",
        "# device = torch.device(DEVICE)\n",
        "# dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# for output_csv_path, modelWithName in models.items():\n",
        "#     modelName, model = modelWithName\n",
        "#     checkpoint_path = f\"./{modelName}.pt\"\n",
        "\n",
        "#     model.load_state_dict(torch.load(checkpoint_path))\n",
        "#     model.to(device)\n",
        "\n",
        "#     path = f\"gdrive/MyDrive/{modelName}.onnx\"\n",
        "#     torch.onnx.export(model,\n",
        "#                       dummy_input,\n",
        "#                       path,\n",
        "#                       export_params=True,\n",
        "#                       opset_version=11,\n",
        "#                       do_constant_folding=True,\n",
        "#                       input_names = ['input'],\n",
        "#                       output_names = ['output'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
