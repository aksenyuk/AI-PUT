{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrQjJyocVHeC"
   },
   "source": [
    "# Lab1: Regular expressions\n",
    "\n",
    "Below you can find several examples of regular expression constructs and texts that will be and won't be matched using a given construct.\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "    <td>Expression</td>\n",
    "    <td>Comment</td>\n",
    "    <td>Example of a match (<strong>in bold</strong>)</td>\n",
    "    <td>Example that is not matched</td>\n",
    "</thead>\n",
    "\n",
    "<tr>\n",
    "    <td>abc</td>\n",
    "    <td>a sequence of letters to find</td>\n",
    "    <td>qw<strong>abc</strong>wer</td>\n",
    "    <td>eedfds</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>[A-Z]</td>\n",
    "    <td>Any capital letter (latin)</td>\n",
    "    <td><strong>A</strong>,<strong>B</strong>,<strong>C</strong>,<strong>Z</strong></td>\n",
    "    <td>1938</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>(abc)</td>\n",
    "    <td>Parentheses introduce groups that can be treated in a special way (e.g., we can expect multiple occurences of a given group). The ( ) chars have special meaning and are not expected to be present in the matched text.</td>\n",
    "    <td><strong>abc</strong></td>\n",
    "    <td>abd</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td>(cat|dog)</td>\n",
    "    <td>alternative - presents multiple alternatives that we allow to be present in text. We expect any of sequences to be present in text.</td>\n",
    "    <td><strong>dog</strong>,<strong>cat</strong></td>\n",
    "    <td>horse</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>abc+</td>\n",
    "    <td>The + sign matches at least 1 occurrence of a character or group preceding that character. Most implementations interpret the repetition characters greedily, matching as many characters as possible, i.e. if we run \"a +\" on the text \"aaaaaa\" that is looking for at least one occurrence of \"a\", the whole string will be returned as a match, because \"aaaaaaa \"is a sequence of 7 consecutive letters a.\n",
    "       <br/> abc+ - will match texts where the letter c after ab is present at least once. <br/> a(bc)+ - will match texts where the letter a is followed by any number of repeated sequences of letters (groups) \"bc\", eg abcbc. <br/> ab [A-Z]+ - will match texts where ab is followed by any number of capital Latin letters.\n",
    "    </td>\n",
    "    <td><strong>abccc</strong></td>\n",
    "    <td>abd</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>abc*</td>\n",
    "    <td>Similar to the example with a plus sign, however, the * sign means zero or more occurrences (in this case 0 or more occurences of the letter c)</td>\n",
    "    <td><strong>ab</strong>efgh, <strong>abcc</strong>d, <strong>abc</strong></td>\n",
    "    <td>accc</td></tr>\n",
    "<tr>\n",
    "    <td>colou?r</td>\n",
    "    <td>sign ? similarly to * and + acts as an indication of the number of repetitions of the preceding character or group. Unlike the previously mentioned, the sign ? means that the character/group \"may or may not occur once\"</td>\n",
    "    <td><strong>color</strong>, <strong>colour</strong></td>\n",
    "    <td>Anything other</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>a(bc){2,4}</td>\n",
    "    <td>Here, too, we consider repetitions of a previous character or group. the first number in a bracket indicates the minimum required number of occurrences of a character / group, the second number indicates the maximum acceptable number of occurrences of a character / group. </td>\n",
    "    <td><strong>abcbcbc</strong></td>\n",
    "    <td>abc, def</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>.+</td>\n",
    "    <td>The period character matches any character. If it is followed by a + sign, the expression matches any string</td>\n",
    "    <td><strong>dopasuje np. taki tekst w całości</strong></td>\n",
    "    <td></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>(?P&lt;name&gt;abc)</td>\n",
    "    <td>Named group - matched pattern, e.g. abc is saved under a variable named name, which can be used to extract parts of an expression (see task 3) </td>\n",
    "    <td><strong>abc</strong></td>\n",
    "    <td>efg</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>^abc</td>\n",
    "    <td>The line start mark ^ requires the pattern abc to match at the beginning of a line. If abc is encountered later in the text - it will not match</td>\n",
    "    <td><strong>abc</strong>dabc</td>\n",
    "    <td>dabc</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>abc$</td>\n",
    "    <td>The line-end $ requires that the abc pattern be matched at the end of a line. If abc is encountered earlier in the text, it will not match</td>\n",
    "    <td>abcd<strong>abc</strong></td>\n",
    "    <td>abcd</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>\\babc\\b</td>\n",
    "    <td>'word boundary', the \\b tells the regex that we expect that at a given position no letter occurs (there may be end of sequence, dot, space, etc., but no letter). This way we ensure that at a given position there is a word boundary. If we wrap some string with \\b, we ensure that matched texts will not be substrings of longer words.</td>\n",
    "    <td><strong>abc</strong> defabc</td><td>abcdef</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvulFqCrVHeF"
   },
   "source": [
    "The examples above illustrate that some characters, such as letters and numbers, are interpreted by regular expressions as normal characters. Others have a special meaning (eg. *? {} () - ^ \\ $). Sometimes, however, we would like some of the special characters to be treated like a normal character, because we would like to match, for example, a star character. To interpret a special character as ordinary - precede the occurrence of this character with a backslash. (e.g. \\\\+)\n",
    "\n",
    "Examples of interesting regular expressions:\n",
    "<ul>\n",
    "    <li> Parsing the sample password on the page: ^[a-z0-9_]{6.18}\\$; - Require that the text (line) begins (^) with a sequence of 6 to 18 occurrences ({6.18}) of characters that belong to the set - lowercase (a-z), numbers (0-9) and underscores. This sequence should be followed by the end of the text (line) (`$`). Example of matching text: <strong> a8dccc__2 </strong> </li>\n",
    "    <li> Extracting color codes, written in hexadecimal form: \\b#[0-9a-fA-F] {6}\\b - match a string beginning with a \"hash\" (#) followed by 6 characters, each of which is a digit, a lowercase letter from the af range or an uppercase letter from the AF range. String must not be a substring of an existing string (\\b), but a separate word. Match example: <strong> #AABB4C </strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Done by:** Sofya Aksenyuk, 150284\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G8itYtRVHeF"
   },
   "source": [
    "# Task 1: Simple regular expressions\n",
    "\n",
    "<div class = \"alert alert-block alert-info\"> Create a regular expression (assign one expression to REGEX variable) that matches all words beginning with an uppercase letter that are at least 4 characters long and at most 6 characters long. The matched text should:\n",
    "<ol>\n",
    "        <li> Have one uppercase (initial) letter. </li>\n",
    "        <li> Each subsequent letter should be lowercase. </li>\n",
    "        <li> The matched text should not contain any characters other than letters. </li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJtr5UPMVHeG"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Expected result:</strong> <br/>\n",
    "dopasowano: Anna <br/>\n",
    "dopasowano: Reddit\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3LgdcoZnVHeG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dopasowano: Anna\n",
      "dopasowano: Reddit\n"
     ]
    }
   ],
   "source": [
    "# Zadanie 1\n",
    "import re\n",
    "\n",
    "test_words = ['zebra', 'krowa', 'Bitcoin', 'Anna', 'Peer2Peer', 'Reddit']\n",
    "\n",
    "REGEX = r'^[A-Z][a-z]{3,5}$'  # tu stwórz wyrażenie regularne np r'test'\n",
    "\n",
    "for word in test_words:\n",
    "    if re.search(REGEX, word):\n",
    "        print(\"dopasowano: {w}\".format(w=word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vumx-M5WVHeH"
   },
   "source": [
    "---\n",
    "# Task 2: Cleaning data\n",
    "<div class = \"alert alert-block alert-info\"> Create a regular expression in the REGEX variable that will match the HTML tags that will be removed using the re.sub function. <br/> The re.sub (substitute) function takes three parameters:\n",
    "    <ol>\n",
    "           <li> What pattern should be matched in order to be replaced with another text. </li>\n",
    "           <li> What to replace the matches (in our case, an empty string, because we want to remove the tags). </li>\n",
    "           <li> A variable containing the text to be searched for. </li>\n",
    "    </ol>\n",
    "           \n",
    "<strong> Tip: </strong> By default, regular expressions are greedy, ie they try to match the longest possible text. For the expression a.\\*a and the text: \"analfabeta\" the whole text will be matched. \\* Will match the longest possible sequence of characters followed by the letter a and preceded by the letter a. <br/>\n",
    "However, you can modify this expression to look for the shortest possible (disjoint) strings that are described by the pattern. In our example it will be ana and abeta. To achieve this, we need to add a question mark after the asterisk: a.\\*? A in the pattern.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7V_cIG9VHeI"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <strong>Oczekiwany rezultat:</strong> <br/>\n",
    "1. To jest tytul 2. A to - Link do google.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7JSXaehRVHeI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. To jest tytul 2. A to - link do google.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "html_text = \"<h1>1. To jest tytul </h1><ul><li class='link'><a href='www.google.pl'>2. A to - link do google.</a></li></ul>\"\n",
    "\n",
    "REGEX = r'<[^>]*>'   # here you should write your regular expression\n",
    "\n",
    "print(re.sub(REGEX, '', html_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0NvQG0xVHeI"
   },
   "source": [
    "# Task 3: Extracting information\n",
    "\n",
    "<div class = \"alert alert-block alert-info\"> Using the mechanism of named groups (see the table at the beginning of the document), write a regular expression that will extract the names of variables and their values from the given url address (patterns of the type? variable_name = variable_value). Part of the task is to create two named groups - the first should be named \"name\" and the second \"val\". These names are used later when displaying the results (see the print function). <br/>\n",
    "Let's assume that the variable name and value can be any string of letters and numbers. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPaiyx9UVHeJ"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Oczekiwany rezultat:</strong> <br/>\n",
    "Variable name: id, value: 1254 <br/>\n",
    "Variable name: name, value: Mike <br/>\n",
    "Variable name: surname, value: Tyson <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BLYzI_hyVHeJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable name: id, value: 1254\n",
      "Variable name: name, value: Mike\n",
      "Variable name: surname, value: Tyson\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "url = \"http://html.net/page.php?id=1254?name=Mike?surname=Tyson\"\n",
    "\n",
    "## Note (for myself): \\w+ == [a-zA-Z0-9_]+\n",
    "REGEX = r'(?P<name>\\w+)\\=(?P<val>\\w+)'\n",
    "\n",
    "for match in re.finditer(REGEX, url):\n",
    "    print(\"Variable name: {name}, value: {val}\".format(\n",
    "        name=match.group('name'), val=match.group('val')\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBs8FmWsVHeJ"
   },
   "source": [
    "# Task 4: Ambiguous text\n",
    "\n",
    "<div class = \"alert alert-block alert-info\">\n",
    "The greatest difficulty in language processing stems from the fact that language is often ambiguous. For example: the period does not always mean the end of a sentence, it is sometimes part of e.g. an abbreviation. A regular expression is proposed for the sample text that can be interpreted as follows:\n",
    "\n",
    "<br/>\n",
    "\n",
    "Match all strings ending with a period (in a non-greedy way [see task 2 tip], we're looking for the \"nearest one\" dot). Then we use the \"positive lookahead\" mechanism https://www.regular-expressions.info/lookaround.html to see what text follows the period. If we see one of the following strings after the period:\n",
    "<ul>\n",
    "<li> space, any letter </li>\n",
    "<li> end of text </li>\n",
    "</ul>\n",
    "we consider this period as the end of the sentence.\n",
    "<br/>\n",
    "The text matched by positive lookahead is not part of the match, it is only a verification whether what is after the match allows us to confirm the decision or not (if the positive lookahead does not match after the period, the expression will not detect the end of the sentence there).\n",
    "\n",
    "<br/>\n",
    "\n",
    "Try to modify this phrase to match the complete, correct sentences. Was the text split correctly? <br/>\n",
    "Modify the expression so that it correctly breaks the given text into sentences (without listing all encountered abbreviations!), or write an explanation why the expression-based approach will not work as a comment in the code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "G_sq_XZjVHeK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Mr.\n",
      " Nowak, I would like to invite you to a conference in the U.S.A.\n",
      " The conference will start on Wed. the 7th of March and will end on Sat. 10 of March.\n",
      " The conference location is Warsaw, Poland.\n",
      " The keynote speaker will be M.D.\n",
      " Obama.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Dear Mr. Nowak, I would like to invite you to a conference in the U.S.A. The conference will start on Wed. the 7th of March and will end on Sat. 10 of March. The conference location is Warsaw, Poland. The keynote speaker will be M.D. Obama.\"\n",
    "\n",
    "REGEX = r'.*?\\.(?=( [A-Z]|$))' \n",
    "# Explanation of the expression from REGEX:\n",
    "# match the shortest text followed by a period (so as not to match all sentences at once by using. *).\n",
    "# See (using positive-lookahead) if the period is followed by a space and a capital letter or the end of the text - if so - we have a sentence!\n",
    "for match in re.finditer(REGEX, text):\n",
    "    print(match.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Explanation:\n",
    "\n",
    "It is **not** possible to split the text in such case without listing all encountered abbreviations, since such an abbreviation may appear, e.g., in the middle of a sentence, so that there's no way to detect whether it is indeed the end of the sentence or not, e.g.:\n",
    "\n",
    "I would like to invite you to a conference in the U.S.A. this Monday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZEFRnGnVHeL"
   },
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "Tasks as repetitive as breaking a text into sentences, words, etc. are usually not implemented from \"scratch\". There are tools that are widely used for language processing, such as:\n",
    "<ul>\n",
    "    <li> SpaCy - https://spacy.io - a relatively new tool that is gaining in popularity. Many things work fine without unnecessary configuration </li>\n",
    "    <li> NLTK - http://www.nltk.org - a very mature tool used mainly for scientific purposes, containing many text corpora.\n",
    "</ul>\n",
    "Both SpaCy and NLTK include tools to solve most basic language processing problems (tokenization, sentence splitting, POS-tagging, Named Entity Recognition (NER), and more).\n",
    "<br/>\n",
    "TASK: Using the documentation, try to split the text into sentences using both NLTK and SpaCy (keyword: \"sentence splitting\").\n",
    "<br/> Which tool did better? Did both / either of the tools get the job done? (Remember that sentences like given are very specific examples to show the difficulty of the procedure - usually the tools do really well). <br/>\n",
    "    \n",
    "<strong> NOTE: If the computer you are using has failed to load the SpaCy model, perform the task using only NLTK. </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "QXeox2oBVHeL"
   },
   "outputs": [],
   "source": [
    "text = \"Dear Mr. Nowak, I would like to invite you to a conference in the U.S.A. The conference will start on Wed., the 7th of March and will end on Sat., the 10th of March. The conference location is Warsaw, Poland. The keynote speaker will be M.D. Mark Obama.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dear Mr. Nowak, I would like to invite you to a conference in the U.S.A.',\n",
       " 'The conference will start on Wed., the 7th of March and will end on Sat., the 10th of March.',\n",
       " 'The conference location is Warsaw, Poland.',\n",
       " 'The keynote speaker will be M.D.',\n",
       " 'Mark Obama.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Note:** Unfortunately, I was unable to load SpaCy model ;("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CXkJXwQVHeL"
   },
   "source": [
    "---\n",
    "\n",
    "# Task 5: Naive Search vs REGEX - processing time\n",
    "\n",
    "<div class = \"alert alert-block alert-info\">\n",
    "When we use a regular expression, it gets converted from text to the appropriate finite state automata in memory. We call the process of this conversion a compilation. <br/> If a given regular expression is used frequently, it is good practice to compile it once - then use the compiled version (see using <strong> re.compile () </strong> in the task). If we do not compile the expression and use it in text form (as a string, as in the previous tasks) - each use of the expression will rebuild the automaton. <br/>\n",
    "In the code below, we compare the two text search methods. In the large text corpus (the bible), we would like to check what male and female names appear in the book. For this purpose, a list of the 2000 most frequently given names in 2017 in the USA (included in the list: names) was compiled and two methods were used:\n",
    "<ol>\n",
    "    <li> Naive, where we iterate over names and check which ones appear in the text </li>\n",
    "    <li> Based on a regular expression in which one automaton searches for all names in one run. </li>\n",
    "</ol>\n",
    "\n",
    "There is no need to write any code for this task, just analyze the code, then run it and see the difference :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "NW8_zZC1VHeM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/sonya/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive method processing time: 4.5450329479936045.\n",
      "The compilation time of the expression 0.03426395599672105. Search time with expression 0.6382871490059188\n",
      "Using regular expressions it is 7.120671245022135 times faster!\n"
     ]
    }
   ],
   "source": [
    "import nltk                                            # We use it to read the text resources (Bible)\n",
    "nltk.download('gutenberg')\n",
    "from timeit import default_timer as timer              # this will help measure time\n",
    "\n",
    "raw_bible = nltk.corpus.gutenberg.raw('bible-kjv.txt') # Read the Bible\n",
    "\n",
    "try:\n",
    "    names = open('names.txt', 'r').read().split(\"\\n\")      # read the list of names into a Python list ['adam', 'ania', ...]\n",
    "except:\n",
    "    # If there is no local file, try to load it from Amazon S3 (may be useful if you are using GoogleColab)\n",
    "    import pandas\n",
    "    import s3fs\n",
    "    df = pandas.read_csv(\"https://dwisniewski-put-pjn.s3.eu-north-1.amazonaws.com/names.txt\", header=None)\n",
    "    names = [name[0] for name in df.values.tolist()]\n",
    "\n",
    "names_found_naive = []\n",
    "names_found_regex = []\n",
    "\n",
    "# naive method\n",
    "start_naive = timer()\n",
    "for name in names:                       # for each name read (1000 names in total)\n",
    "    if name in raw_bible:                # check if the name can be found somewhere in the Bible (ciągu znaków)\n",
    "        names_found_naive.append(name)   # if so, add to a list\n",
    "end_naive = timer()\n",
    "\n",
    "print(\"Naive method processing time: {diff}.\".format(diff=end_naive-start_naive))\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# a method based on regular expressions\n",
    "start_regex = timer()\n",
    "REGEX = '(' + '|'.join(names) + ')'      # creates a big alternative of names: (adam | ania | ...) - which is represented as a prefix tree\n",
    "compiled = re.compile(REGEX)\n",
    "start_compiled = timer()\n",
    "for match in compiled.finditer(raw_bible):\n",
    "    names_found_regex.append(match.groups(0))\n",
    "end_regex = timer()\n",
    "\n",
    "print(\"The compilation time of the expression {comp}. Search time with expression {search}\".format(comp=start_compiled-start_regex, search=end_regex-start_compiled))\n",
    "print(\"Using regular expressions it is {n} times faster!\".format(n=(1.*end_naive-start_naive)/(end_regex-start_compiled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_UMpDVyVHeM"
   },
   "source": [
    "---\n",
    "\n",
    "# Additional materials\n",
    "If you would like to learn more about regular expressions, I suggest to try these webpages:\n",
    "<ol>\n",
    "<li>https://regexone.com - Nice regular expression course with tasks provided.</li>\n",
    "<li>https://regexcrossword.com - Interesting set of tasks in the form of crossword puzzles, some of them are difficult to do :)</li>\n",
    "    <li>https://www.rexegg.com/regex-explosive-quantifiers.html - regular expressions can run REALLY long</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RegularExpressions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
