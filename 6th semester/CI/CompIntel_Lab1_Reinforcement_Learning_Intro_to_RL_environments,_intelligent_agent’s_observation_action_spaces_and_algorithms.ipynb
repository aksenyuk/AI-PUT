{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDeoKl1LZkLA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LExBj87EdLkd"
      },
      "source": [
        "#Differences between the popular environment-agent APIs: OpenAI Gym vs DeepMind Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtLWHLsMdLkf",
        "outputId": "dc6d780e-412a-4248-b5ae-dbc9a82a6d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-acme==0.3.0\n",
            "  Downloading dm-acme-0.3.0.tar.gz (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (1.4.0)\n",
            "Collecting dm-env\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Collecting dm-launchpad==0.4.1\n",
            "  Downloading dm_launchpad-0.4.1-cp38-cp38-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (4.5.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (3.19.6)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (1.51.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (2.2.1)\n",
            "Collecting mock\n",
            "  Downloading mock-5.0.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (1.3.9)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (5.4.8)\n",
            "Building wheels for collected packages: dm-acme\n",
            "  Building wheel for dm-acme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dm-acme: filename=dm_acme-0.3.0-py3-none-any.whl size=561405 sha256=fe2eee50ed70052fdb218c812a90e215b6193bf87ea2b395575864c9dccb0f19\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/d5/68/96139e6e314d8fe12a381976cf631fc1a5b9c546ab00529728\n",
            "Successfully built dm-acme\n",
            "Installing collected packages: mock, dm-env, dm-launchpad, dm-acme\n",
            "Successfully installed dm-acme-0.3.0 dm-env-1.6 dm-launchpad-0.4.1 mock-5.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-acme[reverb]==0.3.0 in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "\u001b[33mWARNING: dm-acme 0.3.0 does not provide the extra 'reverb'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: dm-launchpad==0.4.1 in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (4.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (8.4.0)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (1.6)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (1.3.9)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (2.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (5.4.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (3.19.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (5.0.1)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (1.51.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-acme[tf]==0.3.0 in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: dm-launchpad==0.4.1 in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (1.6)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (4.5.0)\n",
            "Collecting keras==2.7.0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp38-cp38-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.6/489.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-reverb==0.6.1\n",
            "  Downloading dm_reverb-0.6.1-cp38-cp38-manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-sonnet\n",
            "  Downloading dm_sonnet-2.0.1-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.4/268.4 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator==2.7.0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 KB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-probability==0.15.0\n",
            "  Downloading tensorflow_probability-0.15.0-py2.py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-datasets==4.4.0\n",
            "  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (2.2.1)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (1.3.9)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (1.51.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (5.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (5.4.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (3.19.6)\n",
            "Collecting flatbuffers<3.0,>=1.12\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (3.1.0)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (2.11.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (15.0.6.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.31.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.38.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (5.12.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (2.25.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (22.2.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (0.3.6)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (4.64.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0->dm-acme[tf]==0.3.0) (4.4.2)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.8/dist-packages (from dm-sonnet->dm-acme[tf]==0.3.0) (0.8.10)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (4.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (2.16.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (57.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (3.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, flatbuffers, trfl, tensorflow-probability, keras-preprocessing, dm-sonnet, dm-reverb, tensorflow-datasets, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.1.21\n",
            "    Uninstalling flatbuffers-23.1.21:\n",
            "      Successfully uninstalled flatbuffers-23.1.21\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.19.0\n",
            "    Uninstalling tensorflow-probability-0.19.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.19.0\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.8.2\n",
            "    Uninstalling tensorflow-datasets-4.8.2:\n",
            "      Successfully uninstalled tensorflow-datasets-4.8.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.11.0\n",
            "    Uninstalling tensorflow-2.11.0:\n",
            "      Successfully uninstalled tensorflow-2.11.0\n",
            "Successfully installed dm-reverb-0.6.1 dm-sonnet-2.0.1 flatbuffers-2.0.7 keras-2.7.0 keras-preprocessing-1.1.2 tensorflow-2.7.0 tensorflow-datasets-4.4.0 tensorflow-estimator-2.7.0 tensorflow-probability-0.15.0 trfl-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-acme[envs]==0.3.0 in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.1.8)\n",
            "Requirement already satisfied: dm-launchpad==0.4.1 in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (1.22.4)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (1.6)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.25.2)\n",
            "Requirement already satisfied: atari-py in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.2.9)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (4.4.0)\n",
            "Collecting bsuite\n",
            "  Downloading bsuite-0.3.5.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.0/89.0 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dm-control==0.0.364896371\n",
            "  Downloading dm_control-0.0.364896371-py3-none-any.whl (18.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (2.25.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (4.64.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (4.9.2)\n",
            "Requirement already satisfied: protobuf>=3.15.6 in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (3.19.6)\n",
            "Requirement already satisfied: pyopengl>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (3.1.6)\n",
            "Collecting labmaze\n",
            "  Downloading labmaze-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools!=50.0.0 in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (57.4.0)\n",
            "Collecting glfw\n",
            "  Downloading glfw-2.5.6-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (3.0.9)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (1.51.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (5.4.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (1.3.9)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (5.0.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (2.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from atari-py->dm-acme[envs]==0.3.0) (1.15.0)\n",
            "Collecting frozendict\n",
            "  Downloading frozendict-2.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.2/111.2 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from bsuite->dm-acme[envs]==0.3.0) (3.5.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from bsuite->dm-acme[envs]==0.3.0) (1.3.5)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.8/dist-packages (from bsuite->dm-acme[envs]==0.3.0) (0.8.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from bsuite->dm-acme[envs]==0.3.0) (0.18.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym->dm-acme[envs]==0.3.0) (6.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym->dm-acme[envs]==0.3.0) (0.0.8)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (22.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (5.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (0.3.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym->dm-acme[envs]==0.3.0) (3.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (4.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->bsuite->dm-acme[envs]==0.3.0) (2022.7.1)\n",
            "Requirement already satisfied: mizani>=0.7.3 in /usr/local/lib/python3.8/dist-packages (from plotnine->bsuite->dm-acme[envs]==0.3.0) (0.7.3)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.8/dist-packages (from plotnine->bsuite->dm-acme[envs]==0.3.0) (0.12.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from plotnine->bsuite->dm-acme[envs]==0.3.0) (0.5.3)\n",
            "Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from plotnine->bsuite->dm-acme[envs]==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->bsuite->dm-acme[envs]==0.3.0) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->bsuite->dm-acme[envs]==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->bsuite->dm-acme[envs]==0.3.0) (2023.2.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->bsuite->dm-acme[envs]==0.3.0) (2.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets->dm-acme[envs]==0.3.0) (1.58.0)\n",
            "Requirement already satisfied: palettable in /usr/local/lib/python3.8/dist-packages (from mizani>=0.7.3->plotnine->bsuite->dm-acme[envs]==0.3.0) (3.3.0)\n",
            "Building wheels for collected packages: bsuite\n",
            "  Building wheel for bsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bsuite: filename=bsuite-0.3.5-py3-none-any.whl size=245537 sha256=4ce9a3a373d375cd3fedfab8a061d60d4b7bc9c3445c70febe2bb497b72515d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8f/a5/60cb9cebd2d442e5afbda0c22315ea00329ffaf83a648d5b79\n",
            "Successfully built bsuite\n",
            "Installing collected packages: glfw, labmaze, frozendict, dm-control, ale-py, bsuite\n",
            "Successfully installed ale-py-0.7.5 bsuite-0.3.5 dm-control-0.0.364896371 frozendict-2.3.5 glfw-2.5.6 labmaze-1.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install dm-acme==0.3.0\n",
        "!pip install dm-acme[reverb]==0.3.0\n",
        "!pip install dm-acme[tf]==0.3.0\n",
        "!pip install dm-acme[envs]==0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-uBIUwydLkj",
        "outputId": "3750c8ea-c503-451d-911f-f70dcfe8818b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.8/dist-packages (1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dm-env) (1.22.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-env) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from dm-env) (1.4.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 780 kB of archives.\n",
            "After this operation, 2,271 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.6 [780 kB]\n",
            "Fetched 780 kB in 1s (890 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 128221 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.20.13-1ubuntu1~20.04.6_amd64.deb ...\n",
            "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.6) ...\n",
            "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.6) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio) (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "#@title Install requirements  { form-width: \"30%\" }\n",
        "\n",
        "!pip install dm-env\n",
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "!pip install imageio\n",
        "\n",
        "#rom IPython.display import clear_output\n",
        "#clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO2_xFLodLkm",
        "outputId": "4782191d-9b33-471a-c10c-431dbdaaeb0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "xvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym) (6.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym) (1.22.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym) (3.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PILLOW in /usr/local/lib/python3.8/dist-packages (8.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyglet\n",
            "  Downloading pyglet-2.0.5-py3-none-any.whl (831 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.3/831.3 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "Successfully installed pyglet-2.0.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        }
      ],
      "source": [
        "#@title Install necessary dependencies.\n",
        "\n",
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "#!pip install 'gym==0.10.11'\n",
        "!pip install gym\n",
        "!pip install imageio\n",
        "!pip install PILLOW\n",
        "#!pip install 'pyglet==1.3.2'\n",
        "!pip install pyglet\n",
        "!pip install pyvirtualdisplay\n",
        "\n",
        "#!pip install dm-acme\n",
        "#!pip install dm-acme[reverb]\n",
        "#!pip install dm-acme[tf]\n",
        "#!pip install dm-acme[envs]\n",
        "\n",
        "#from IPython.display import clear_output\n",
        "#clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09RoECp0dLkp",
        "outputId": "b1036188-ecb2-4e10-edfe-ed68eaa1c1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-acme==0.3.0 in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (4.5.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (0.1.8)\n",
            "Requirement already satisfied: dm-launchpad==0.4.1 in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from dm-acme==0.3.0) (8.4.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (1.51.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (3.19.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (5.0.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (2.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (5.4.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme==0.3.0) (1.3.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-acme[reverb]==0.3.0 in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "\u001b[33mWARNING: dm-acme 0.3.0 does not provide the extra 'reverb'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (8.4.0)\n",
            "Requirement already satisfied: dm-launchpad==0.4.1 in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (4.5.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (1.22.4)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.8/dist-packages (from dm-acme[reverb]==0.3.0) (1.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (5.4.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (2.2.1)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (1.3.9)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (5.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (3.19.6)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[reverb]==0.3.0) (1.51.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-acme[tf]==0.3.0 in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (0.1.8)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (1.6)\n",
            "Requirement already satisfied: dm-launchpad==0.4.1 in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-probability==0.15.0 in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (0.15.0)\n",
            "Requirement already satisfied: dm-sonnet in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (2.0.1)\n",
            "Requirement already satisfied: trfl in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (1.2.0)\n",
            "Requirement already satisfied: dm-reverb==0.6.1 in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (0.6.1)\n",
            "Requirement already satisfied: tensorflow-datasets==4.4.0 in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (4.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator==2.7.0 in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (2.7.0)\n",
            "Requirement already satisfied: tensorflow==2.7.0 in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (2.7.0)\n",
            "Requirement already satisfied: keras==2.7.0 in /usr/local/lib/python3.8/dist-packages (from dm-acme[tf]==0.3.0) (2.7.0)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (1.3.9)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (3.19.6)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (2.2.1)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (5.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (1.51.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[tf]==0.3.0) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.31.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (2.11.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.38.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (2.0.7)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->dm-acme[tf]==0.3.0) (15.0.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (5.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (2.25.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (22.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (0.3.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0->dm-acme[tf]==0.3.0) (4.4.2)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.8/dist-packages (from dm-sonnet->dm-acme[tf]==0.3.0) (0.8.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (1.26.14)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (2.2.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (2.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (3.4.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (3.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.4.0->dm-acme[tf]==0.3.0) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->dm-acme[tf]==0.3.0) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-acme[envs]==0.3.0 in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (8.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (4.5.0)\n",
            "Requirement already satisfied: dm-launchpad==0.4.1 in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (1.6)\n",
            "Requirement already satisfied: atari-py in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.2.9)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.25.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (4.4.0)\n",
            "Requirement already satisfied: bsuite in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.3.5)\n",
            "Requirement already satisfied: dm-control==0.0.364896371 in /usr/local/lib/python3.8/dist-packages (from dm-acme[envs]==0.3.0) (0.0.364896371)\n",
            "Requirement already satisfied: setuptools!=50.0.0 in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (57.4.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (2.5.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (4.9.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (3.1.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (3.0.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (4.64.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: pyopengl>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (2.25.1)\n",
            "Requirement already satisfied: protobuf>=3.15.6 in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (3.19.6)\n",
            "Requirement already satisfied: labmaze in /usr/local/lib/python3.8/dist-packages (from dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (1.0.6)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (5.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (5.4.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (2.2.1)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (1.51.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-launchpad==0.4.1->dm-acme[envs]==0.3.0) (1.3.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from atari-py->dm-acme[envs]==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.8/dist-packages (from bsuite->dm-acme[envs]==0.3.0) (0.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from bsuite->dm-acme[envs]==0.3.0) (3.5.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from bsuite->dm-acme[envs]==0.3.0) (1.3.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from bsuite->dm-acme[envs]==0.3.0) (0.18.3)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.8/dist-packages (from bsuite->dm-acme[envs]==0.3.0) (2.3.5)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[atari]->dm-acme[envs]==0.3.0) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[atari]->dm-acme[envs]==0.3.0) (6.0.0)\n",
            "Requirement already satisfied: ale-py~=0.7.5 in /usr/local/lib/python3.8/dist-packages (from gym[atari]->dm-acme[envs]==0.3.0) (0.7.5)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (22.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (0.3.6)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->dm-acme[envs]==0.3.0) (5.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[atari]->dm-acme[envs]==0.3.0) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->dm-control==0.0.364896371->dm-acme[envs]==0.3.0) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bsuite->dm-acme[envs]==0.3.0) (23.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->bsuite->dm-acme[envs]==0.3.0) (2022.7.1)\n",
            "Requirement already satisfied: mizani>=0.7.3 in /usr/local/lib/python3.8/dist-packages (from plotnine->bsuite->dm-acme[envs]==0.3.0) (0.7.3)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.8/dist-packages (from plotnine->bsuite->dm-acme[envs]==0.3.0) (0.12.2)\n",
            "Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from plotnine->bsuite->dm-acme[envs]==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from plotnine->bsuite->dm-acme[envs]==0.3.0) (0.5.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->bsuite->dm-acme[envs]==0.3.0) (2023.2.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->bsuite->dm-acme[envs]==0.3.0) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->bsuite->dm-acme[envs]==0.3.0) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->bsuite->dm-acme[envs]==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets->dm-acme[envs]==0.3.0) (1.58.0)\n",
            "Requirement already satisfied: palettable in /usr/local/lib/python3.8/dist-packages (from mizani>=0.7.3->plotnine->bsuite->dm-acme[envs]==0.3.0) (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dm-acme==0.3.0\n",
        "!pip install dm-acme[reverb]==0.3.0\n",
        "!pip install dm-acme[tf]==0.3.0\n",
        "!pip install dm-acme[envs]==0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LmUgAQ-NdLks"
      },
      "outputs": [],
      "source": [
        "#@title Import modules.\n",
        "#python3\n",
        "\n",
        "%%capture\n",
        "import copy\n",
        "import pyvirtualdisplay\n",
        "import imageio \n",
        "import base64\n",
        "import IPython\n",
        "\n",
        "from acme import environment_loop\n",
        "from acme.tf import networks\n",
        "from acme.adders import reverb as adders\n",
        "from acme.agents.tf import actors as actors\n",
        "from acme.datasets import reverb as datasets\n",
        "from acme.wrappers import gym_wrapper\n",
        "from acme import specs\n",
        "from acme import wrappers\n",
        "from acme.agents.tf import d4pg\n",
        "from acme.agents import agent\n",
        "from acme.tf import utils as tf2_utils\n",
        "from acme.utils import loggers\n",
        "\n",
        "import gym \n",
        "import dm_env\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import reverb\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set up a virtual display for rendering OpenAI gym environments.\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NwGUY218dLkv"
      },
      "outputs": [],
      "source": [
        "#@title Import modules  { form-width: \"30%\" }\n",
        "\n",
        "import IPython\n",
        "from typing import Callable, Optional, Sequence\n",
        "\n",
        "import acme\n",
        "from acme import environment_loop\n",
        "from acme import specs\n",
        "from acme import wrappers\n",
        "from acme.utils import tree_utils\n",
        "from acme.agents.tf import dqn\n",
        "# from acme.utils import counting\n",
        "from acme.utils import loggers\n",
        "import base64\n",
        "import collections\n",
        "import dm_env\n",
        "import enum\n",
        "# import functools\n",
        "import gym\n",
        "# import io\n",
        "import imageio\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sonnet as snt\n",
        "import tensorflow.compat.v2 as tf\n",
        "tf.enable_v2_behavior()\n",
        "import tensorflow_probability as tfp\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=1)\n",
        "\n",
        "plt.style.use('seaborn-notebook')\n",
        "plt.style.use('seaborn-whitegrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frzEbvPgdLkx"
      },
      "source": [
        "### Acme agent interface (from \"RL MLSS Tutorial\" [https://colab.research.google.com/github/feryal/rl_mlss_2020/blob/master/RL_Tutorial_MLSS_2020.ipynb])\n",
        "\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?id=1T7FTpA9RgDYFkciDFZK4brNyURZN_ZGp\" width=\"500\" /></center>\n",
        "\n",
        "Each agent implements the following functions:\n",
        "\n",
        "```python\n",
        "class Agent(acme.Actor):\n",
        "  def __init__(self, number_of_actions, number_of_states, ...):\n",
        "    \"\"\"Provides the agent the number of actions and number of states.\"\"\"\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    \"\"\"Generates actions from observations.\"\"\"\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    \"\"\"Records the initial timestep in a trajectory.\"\"\"\n",
        "  \n",
        "  def observe(self, action, next_timestep):\n",
        "    \"\"\"Records the transition which occurred from taking an action.\"\"\"\n",
        "\n",
        "  def update(self):\n",
        "    \"\"\"Updates the agent's internals to potentially change its behavior.\"\"\"\n",
        "```\n",
        "\n",
        "For now just one remark on the `observe()` function: In the last method, the `next_timestep` provides the `reward`, `discount`, and `observation` that resulted from selecting `action`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OZIiwK9EdLkz"
      },
      "outputs": [],
      "source": [
        "#@title Implement the run loop  { form-width: \"30%\" }\n",
        "\n",
        "def run_loop(\n",
        "    environment: dm_env.Environment,\n",
        "    agent: acme.Actor,\n",
        "    num_episodes: Optional[int] = None,\n",
        "    num_steps: Optional[int] = None,\n",
        "    logger_time_delta: float = .25,\n",
        "    label: str = 'training_loop',\n",
        "    log_loss: bool = False,\n",
        "):\n",
        "  \"\"\"Perform the run loop.\n",
        "\n",
        "  We are following the Acme run loop.\n",
        "\n",
        "  Run the environment loop for `num_episodes` episodes. Each episode is itself\n",
        "  a loop which interacts first with the environment to get an observation and\n",
        "  then give that observation to the agent in order to retrieve an action. Upon\n",
        "  termination of an episode a new episode will be started. If the number of\n",
        "  episodes is not given then this will interact with the environment\n",
        "  infinitely.\n",
        "\n",
        "  Args:\n",
        "    environment: dm_env.Environment used to generate trajectories.\n",
        "    agent: acme.Actor for selecting actions in the run loop.\n",
        "    num_steps: number of steps to run the loop for. If `None` (default), runs\n",
        "      without limit.\n",
        "    num_episodes: number of episodes to run the loop for. If `None` (default),\n",
        "      runs without limit.\n",
        "    logger_time_delta: time interval (in seconds) between consecutive logging\n",
        "      steps.\n",
        "    label: optional label used at logging steps.\n",
        "  \"\"\"\n",
        "  logger = loggers.TerminalLogger(label=label, time_delta=logger_time_delta)\n",
        "  iterator = range(num_episodes) if num_episodes else itertools.count()\n",
        "  all_returns = []\n",
        "  \n",
        "  num_total_steps = 0\n",
        "  for episode in iterator:\n",
        "    # Reset any counts and start the environment.\n",
        "    start_time = time.time()\n",
        "    episode_steps = 0\n",
        "    episode_return = 0\n",
        "    episode_loss = 0\n",
        "\n",
        "    timestep = environment.reset()\n",
        "    \n",
        "    # Make the first observation.\n",
        "    agent.observe_first(timestep)\n",
        "\n",
        "    # Run an episode.\n",
        "    while not timestep.last():\n",
        "      # Generate an action from the agent's policy and step the environment.\n",
        "      action = agent.select_action(timestep.observation)\n",
        "      timestep = environment.step(action)\n",
        "\n",
        "      # Have the agent observe the timestep and let the agent update itself.\n",
        "      agent.observe(action, next_timestep=timestep)\n",
        "      agent.update()\n",
        "\n",
        "      # Book-keeping.\n",
        "      episode_steps += 1\n",
        "      num_total_steps += 1\n",
        "      episode_return += timestep.reward\n",
        "\n",
        "      if log_loss:\n",
        "        episode_loss += agent.last_loss\n",
        "\n",
        "      if num_steps is not None and num_total_steps >= num_steps:\n",
        "        break\n",
        "\n",
        "    # Collect the results and combine with counts.\n",
        "    steps_per_second = episode_steps / (time.time() - start_time)\n",
        "    result = {\n",
        "        'episode': episode,\n",
        "        'episode_length': episode_steps,\n",
        "        'episode_return': episode_return,\n",
        "    }\n",
        "    if log_loss:\n",
        "      result['loss_avg'] = episode_loss / episode_steps\n",
        "\n",
        "    all_returns.append(episode_return)\n",
        "\n",
        "    # Log the given results.\n",
        "    logger.write(result)\n",
        "    \n",
        "    if num_steps is not None and num_total_steps >= num_steps:\n",
        "      break\n",
        "\n",
        "  return all_returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jdhr4zncdLk1"
      },
      "outputs": [],
      "source": [
        "# Create the environment.\n",
        "#environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v0'))\n",
        "environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v1'))\n",
        "environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "\n",
        "# Get the environment's specification.\n",
        "environment_spec = acme.specs.make_environment_spec(environment)\n",
        "\n",
        "# Build the agent's network.\n",
        "q_network = snt.Sequential([\n",
        "    snt.Flatten(),\n",
        "    snt.nets.MLP([100, environment_spec.actions.num_values])\n",
        "])\n",
        "\n",
        "learning_rate = 1e-3\n",
        "epsilon = 0.1 \n",
        "\n",
        "# Create the agent.\n",
        "agent = dqn.DQN(\n",
        "    environment_spec=environment_spec,\n",
        "    network=q_network,\n",
        "    batch_size=64,\n",
        "    epsilon=epsilon,\n",
        "    learning_rate=learning_rate,\n",
        "    min_replay_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-iwatSWdLk2",
        "outputId": "06045bf3-af22-4fe5-9dff-bd6257088f22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EnvironmentSpec(observations=BoundedArray(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.800e+00 -3.403e+38 -4.189e-01 -3.403e+38], maximum=[4.800e+00 3.403e+38 4.189e-01 3.403e+38]), actions=DiscreteArray(shape=(), dtype=int32, name=action, minimum=0, maximum=1, num_values=2), rewards=Array(shape=(), dtype=dtype('float32'), name='reward'), discounts=BoundedArray(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "acme.specs.make_environment_spec(environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sbRxa2S0ZYXk"
      },
      "outputs": [],
      "source": [
        "def query_environment(name):\n",
        "  env = gym.make(name)\n",
        "  spec = gym.spec(name)\n",
        "  print(f\"Action Space: {env.action_space}\")\n",
        "  print(f\"Observation Space: {env.observation_space}\")\n",
        "  print(f\"Max Episode Steps: {spec.max_episode_steps}\")\n",
        "  print(f\"Nondeterministic: {spec.nondeterministic}\")\n",
        "  print(f\"Reward Range: {env.reward_range}\")\n",
        "  print(f\"Reward Threshold: {spec.reward_threshold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyggjE9ydLk5",
        "outputId": "20bd975e-1f75-404b-8af5-c0912ba77793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(2)\n",
            "Observation Space: Box([-4.800e+00 -3.403e+38 -4.189e-01 -3.403e+38], [4.800e+00 3.403e+38 4.189e-01 3.403e+38], (4,), float32)\n",
            "Max Episode Steps: 500\n",
            "Nondeterministic: False\n",
            "Reward Range: (-inf, inf)\n",
            "Reward Threshold: 475.0\n"
          ]
        }
      ],
      "source": [
        "query_environment('CartPole-v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZIPB-3bdLk7"
      },
      "outputs": [],
      "source": [
        "#@title Construct the agent and run the training loop { form-width: \"30%\" }\n",
        "\n",
        "\n",
        "num_episodes = 500  # @param {type: \"number\"}\n",
        "epsilon = 0.1  # @param {type: \"number\"}\n",
        "learning_rate = 1e-3  # @param {type: \"number\"}\n",
        "\n",
        "# Create the environment.\n",
        "#environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v0'))\n",
        "environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v1'))\n",
        "environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "\n",
        "# Get the environment's specification.\n",
        "environment_spec = acme.specs.make_environment_spec(environment)\n",
        "\n",
        "# Build the agent's network.\n",
        "q_network = snt.Sequential([\n",
        "    snt.Flatten(),\n",
        "    snt.nets.MLP([100, environment_spec.actions.num_values])\n",
        "])\n",
        "\n",
        "# Create the agent.\n",
        "agent = dqn.DQN(\n",
        "    environment_spec=environment_spec,\n",
        "    network=q_network,\n",
        "    batch_size=64,\n",
        "    epsilon=epsilon,\n",
        "    learning_rate=learning_rate,\n",
        "    min_replay_size=100)\n",
        "\n",
        "# Train the agent.\n",
        "returns = run_loop(environment=environment, agent=agent, num_episodes=num_episodes, \n",
        "         logger_time_delta=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAzj96w-dLk8"
      },
      "outputs": [],
      "source": [
        "#@title Visualise the training curve { form-width: \"30%\" }\n",
        "\n",
        "# Compute rolling average over returns\n",
        "returns_avg = pd.Series(returns).rolling(10, center=True).mean()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(len(returns)), returns_avg)\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Episode return');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEBp74eQdLk9"
      },
      "outputs": [],
      "source": [
        "frame = environment.environment.render(mode='rgb_array')\n",
        "plt.imshow(frame)\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEPNPMYZdLk-"
      },
      "outputs": [],
      "source": [
        "def display_video(frames, filename='temp.mp4'):\n",
        "  \"\"\"Save and display video.\"\"\"\n",
        "  # Write video\n",
        "  with imageio.get_writer(filename, fps=60) as video:\n",
        "    for frame in frames:\n",
        "      video.append_data(frame)\n",
        "  # Read video and display the video\n",
        "  video = open(filename, 'rb').read()\n",
        "  b64_video = base64.b64encode(video)\n",
        "  video_tag = ('<video  width=\"320\" height=\"240\" controls alt=\"test\" '\n",
        "               'src=\"data:video/mp4;base64,{0}\">').format(b64_video.decode())\n",
        "  return IPython.display.HTML(video_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiMVkR5cdLk_"
      },
      "outputs": [],
      "source": [
        "# Create the environment.\n",
        "environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v1'))\n",
        "environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "\n",
        "\n",
        "# Run the actor in the environment for desired number of steps.\n",
        "frames = []\n",
        "#num_steps = 500\n",
        "num_steps = 1000\n",
        "timestep = environment.reset()\n",
        "reward_history = []\n",
        "error_history = []\n",
        "discount_history = []\n",
        "\n",
        "for _ in range(num_steps):\n",
        "  frame = environment.environment.render(mode='rgb_array')\n",
        "  frames.append(frame)\n",
        "  action = agent.select_action(timestep.observation)\n",
        "  timestep = environment.step(action)\n",
        "  reward_history.append(timestep.reward)\n",
        "  error_history.append(timestep.observation[2])\n",
        "  discount_history.append(timestep.discount)\n",
        "\n",
        "# Save video of the behaviour.\n",
        "display_video(np.array(frames))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3lofSvndLlA"
      },
      "outputs": [],
      "source": [
        "plt.plot(reward_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-_FWVyWdLlC"
      },
      "outputs": [],
      "source": [
        "plt.plot(error_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYB0FfxndLlD"
      },
      "outputs": [],
      "source": [
        "plt.plot(discount_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6FjiKWGdLlD"
      },
      "outputs": [],
      "source": [
        "discount_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0KUEaKeGU5S"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDQrs2nGdLlF"
      },
      "outputs": [],
      "source": [
        "# Create the environment.\n",
        "environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v1'))\n",
        "environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "\n",
        "\n",
        "# Run the actor in the environment for desired number of steps.\n",
        "frames = []\n",
        "#num_steps = 500\n",
        "num_steps = 1000\n",
        "timestep = environment.reset()\n",
        "reward_history = []\n",
        "error_history = []\n",
        "\n",
        "integral = 0\n",
        "derivative = 0\n",
        "prev_error = 0\n",
        "#pid_history = []\n",
        "#state_history = []\n",
        "#masked_state_history = []\n",
        "#action_history = []\n",
        "#masked_pid_history = []\n",
        "\n",
        "\n",
        "P, I, D = 0.02, 0.01, 0.5\n",
        "\n",
        "\n",
        "for _ in range(num_steps):\n",
        "  frame = environment.environment.render(mode='rgb_array')\n",
        "  frames.append(frame)\n",
        "  error = timestep.observation[2]  # Why is it so simple?\n",
        "  error_history.append(error)\n",
        "  integral += error\n",
        "  derivative = error - prev_error\n",
        "  prev_error = error\n",
        "  pid = P * error + I * integral + D * derivative\n",
        "  action = sigmoid(pid)\n",
        "  action = np.round(action).astype(np.int32)\n",
        "  timestep = environment.step(action)\n",
        "  reward_history.append(timestep.reward)\n",
        "\n",
        "# Save video of the behaviour.\n",
        "display_video(np.array(frames))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZecO7o4dLlG"
      },
      "outputs": [],
      "source": [
        "plt.plot(error_history)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6bqJesHdLlI"
      },
      "outputs": [],
      "source": [
        "!pip freeze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2ckxTssdLlJ"
      },
      "source": [
        "A working set of packages: \n",
        "absl-py==1.0.0\n",
        "alabaster==0.7.12\n",
        "albumentations==0.1.12\n",
        "altair==4.2.0\n",
        "appdirs==1.4.4\n",
        "argon2-cffi==21.3.0\n",
        "argon2-cffi-bindings==21.2.0\n",
        "arviz==0.11.4\n",
        "astor==0.8.1\n",
        "astropy==4.3.1\n",
        "astunparse==1.6.3\n",
        "atari-py==0.2.9\n",
        "atomicwrites==1.4.0\n",
        "attrs==21.4.0\n",
        "audioread==2.1.9\n",
        "autograd==1.3\n",
        "Babel==2.9.1\n",
        "backcall==0.2.0\n",
        "beautifulsoup4==4.6.3\n",
        "bleach==4.1.0\n",
        "blis==0.4.1\n",
        "bokeh==2.3.3\n",
        "Bottleneck==1.3.4\n",
        "branca==0.4.2\n",
        "bs4==0.0.1\n",
        "bsuite==0.3.5\n",
        "CacheControl==0.12.10\n",
        "cached-property==1.5.2\n",
        "cachetools==4.2.4\n",
        "catalogue==1.0.0\n",
        "certifi==2021.10.8\n",
        "cffi==1.15.0\n",
        "cftime==1.5.2\n",
        "chardet==3.0.4\n",
        "charset-normalizer==2.0.12\n",
        "click==7.1.2\n",
        "cloudpickle==1.3.0\n",
        "cmake==3.12.0\n",
        "cmdstanpy==0.9.5\n",
        "colorcet==3.0.0\n",
        "colorlover==0.3.0\n",
        "community==1.0.0b1\n",
        "contextlib2==0.5.5\n",
        "convertdate==2.4.0\n",
        "coverage==3.7.1\n",
        "coveralls==0.5\n",
        "crcmod==1.7\n",
        "cufflinks==0.17.3\n",
        "cvxopt==1.2.7\n",
        "cvxpy==1.0.31\n",
        "cycler==0.11.0\n",
        "cymem==2.0.6\n",
        "Cython==0.29.28\n",
        "daft==0.0.4\n",
        "dask==2.12.0\n",
        "datascience==0.10.6\n",
        "debugpy==1.0.0\n",
        "decorator==4.4.2\n",
        "defusedxml==0.7.1\n",
        "descartes==1.1.0\n",
        "dill==0.3.4\n",
        "distributed==1.25.3\n",
        "dlib @ file:///dlib-19.18.0-cp37-cp37m-linux_x86_64.whl\n",
        "dm-acme==0.3.0\n",
        "dm-control==0.0.364896371\n",
        "dm-env==1.5\n",
        "dm-launchpad==0.4.1\n",
        "dm-reverb==0.6.1\n",
        "dm-sonnet==2.0.0\n",
        "dm-tree==0.1.6\n",
        "docopt==0.6.2\n",
        "docutils==0.17.1\n",
        "dopamine-rl==1.0.5\n",
        "earthengine-api==0.1.300\n",
        "easydict==1.9\n",
        "ecos==2.0.10\n",
        "editdistance==0.5.3\n",
        "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\n",
        "entrypoints==0.4\n",
        "ephem==4.1.3\n",
        "et-xmlfile==1.1.0\n",
        "fa2==0.3.5\n",
        "fastai==1.0.61\n",
        "fastdtw==0.3.4\n",
        "fastprogress==1.0.2\n",
        "fastrlock==0.8\n",
        "fbprophet==0.7.1\n",
        "feather-format==0.4.1\n",
        "filelock==3.6.0\n",
        "firebase-admin==4.4.0\n",
        "fix-yahoo-finance==0.0.22\n",
        "Flask==1.1.4\n",
        "flatbuffers==2.0\n",
        "folium==0.8.3\n",
        "frozendict==2.3.0\n",
        "future==0.16.0\n",
        "gast==0.4.0\n",
        "GDAL==2.2.2\n",
        "gdown==4.2.2\n",
        "gensim==3.6.0\n",
        "geographiclib==1.52\n",
        "geopy==1.17.0\n",
        "gin-config==0.5.0\n",
        "glfw==2.5.1\n",
        "glob2==0.7\n",
        "google==2.0.3\n",
        "google-api-core==1.26.3\n",
        "google-api-python-client==1.12.10\n",
        "google-auth==1.35.0\n",
        "google-auth-httplib2==0.0.4\n",
        "google-auth-oauthlib==0.4.6\n",
        "google-cloud-bigquery==1.21.0\n",
        "google-cloud-bigquery-storage==1.1.0\n",
        "google-cloud-core==1.0.3\n",
        "google-cloud-datastore==1.8.0\n",
        "google-cloud-firestore==1.7.0\n",
        "google-cloud-language==1.2.0\n",
        "google-cloud-storage==1.18.1\n",
        "google-cloud-translate==1.5.0\n",
        "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n",
        "google-pasta==0.2.0\n",
        "google-resumable-media==0.4.1\n",
        "googleapis-common-protos==1.55.0\n",
        "googledrivedownloader==0.4\n",
        "graphviz==0.10.1\n",
        "greenlet==1.1.2\n",
        "grpcio==1.44.0\n",
        "gspread==3.4.2\n",
        "gspread-dataframe==3.0.8\n",
        "gym==0.17.3\n",
        "h5py==3.1.0\n",
        "HeapDict==1.0.1\n",
        "hijri-converter==2.2.3\n",
        "holidays==0.10.5.2\n",
        "holoviews==1.14.8\n",
        "html5lib==1.0.1\n",
        "httpimport==0.5.18\n",
        "httplib2==0.17.4\n",
        "httplib2shim==0.0.3\n",
        "humanize==0.5.1\n",
        "hyperopt==0.1.2\n",
        "ideep4py==2.0.0.post3\n",
        "idna==2.10\n",
        "imageio==2.4.1\n",
        "imagesize==1.3.0\n",
        "imbalanced-learn==0.8.1\n",
        "imblearn==0.0\n",
        "imgaug==0.2.9\n",
        "importlib-metadata==4.11.1\n",
        "importlib-resources==5.4.0\n",
        "imutils==0.5.4\n",
        "inflect==2.1.0\n",
        "iniconfig==1.1.1\n",
        "intel-openmp==2022.0.2\n",
        "intervaltree==2.1.0\n",
        "ipykernel==4.10.1\n",
        "ipython==5.5.0\n",
        "ipython-genutils==0.2.0\n",
        "ipython-sql==0.3.9\n",
        "ipywidgets==7.6.5\n",
        "itsdangerous==1.1.0\n",
        "jax==0.3.1\n",
        "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.0+cuda11.cudnn805-cp37-none-manylinux2010_x86_64.whl\n",
        "jedi==0.18.1\n",
        "jieba==0.42.1\n",
        "Jinja2==2.11.3\n",
        "joblib==1.1.0\n",
        "jpeg4py==0.1.4\n",
        "jsonschema==4.3.3\n",
        "jupyter==1.0.0\n",
        "jupyter-client==5.3.5\n",
        "jupyter-console==5.2.0\n",
        "jupyter-core==4.9.2\n",
        "jupyterlab-pygments==0.1.2\n",
        "jupyterlab-widgets==1.0.2\n",
        "kaggle==1.5.12\n",
        "kapre==0.3.7\n",
        "keras==2.7.0\n",
        "Keras-Preprocessing==1.1.2\n",
        "keras-vis==0.4.1\n",
        "kiwisolver==1.3.2\n",
        "korean-lunar-calendar==0.2.1\n",
        "labmaze==1.0.5\n",
        "libclang==13.0.0\n",
        "librosa==0.8.1\n",
        "lightgbm==2.2.3\n",
        "llvmlite==0.34.0\n",
        "lmdb==0.99\n",
        "LunarCalendar==0.0.9\n",
        "lxml==4.2.6\n",
        "Markdown==3.3.6\n",
        "MarkupSafe==2.0.1\n",
        "matplotlib==3.2.2\n",
        "matplotlib-inline==0.1.3\n",
        "matplotlib-venn==0.11.6\n",
        "missingno==0.5.0\n",
        "mistune==0.8.4\n",
        "mizani==0.6.0\n",
        "mkl==2019.0\n",
        "mlxtend==0.14.0\n",
        "mock==4.0.3\n",
        "more-itertools==8.12.0\n",
        "moviepy==0.2.3.5\n",
        "mpmath==1.2.1\n",
        "msgpack==1.0.3\n",
        "multiprocess==0.70.12.2\n",
        "multitasking==0.0.10\n",
        "murmurhash==1.0.6\n",
        "music21==5.5.0\n",
        "natsort==5.5.0\n",
        "nbclient==0.5.11\n",
        "nbconvert==5.6.1\n",
        "nbformat==5.1.3\n",
        "nest-asyncio==1.5.4\n",
        "netCDF4==1.5.8\n",
        "networkx==2.6.3\n",
        "nibabel==3.0.2\n",
        "nltk==3.2.5\n",
        "notebook==5.3.1\n",
        "numba==0.51.2\n",
        "numexpr==2.8.1\n",
        "numpy==1.21.5\n",
        "nvidia-ml-py3==7.352.0\n",
        "oauth2client==4.1.3\n",
        "oauthlib==3.2.0\n",
        "okgrade==0.4.3\n",
        "opencv-contrib-python==4.1.2.30\n",
        "opencv-python==4.1.2.30\n",
        "openpyxl==3.0.9\n",
        "opt-einsum==3.3.0\n",
        "osqp==0.6.2.post0\n",
        "packaging==21.3\n",
        "palettable==3.3.0\n",
        "pandas==1.3.5\n",
        "pandas-datareader==0.9.0\n",
        "pandas-gbq==0.13.3\n",
        "pandas-profiling==1.4.1\n",
        "pandocfilters==1.5.0\n",
        "panel==0.12.1\n",
        "param==1.12.0\n",
        "parso==0.8.3\n",
        "pathlib==1.0.1\n",
        "patsy==0.5.2\n",
        "pep517==0.12.0\n",
        "pexpect==4.8.0\n",
        "pickleshare==0.7.5\n",
        "Pillow==7.1.2\n",
        "pip-tools==6.2.0\n",
        "plac==1.1.3\n",
        "plotly==5.5.0\n",
        "plotnine==0.6.0\n",
        "pluggy==0.7.1\n",
        "pooch==1.6.0\n",
        "portpicker==1.3.9\n",
        "prefetch-generator==1.0.1\n",
        "preshed==3.0.6\n",
        "prettytable==3.1.1\n",
        "progressbar2==3.38.0\n",
        "prometheus-client==0.13.1\n",
        "promise==2.3\n",
        "prompt-toolkit==1.0.18\n",
        "protobuf==3.17.3\n",
        "psutil==5.4.8\n",
        "psycopg2==2.7.6.1\n",
        "ptyprocess==0.7.0\n",
        "py==1.11.0\n",
        "pyarrow==6.0.1\n",
        "pyasn1==0.4.8\n",
        "pyasn1-modules==0.2.8\n",
        "pycocotools==2.0.4\n",
        "pycparser==2.21\n",
        "pyct==0.4.8\n",
        "pydata-google-auth==1.3.0\n",
        "pydot==1.3.0\n",
        "pydot-ng==2.0.0\n",
        "pydotplus==2.0.2\n",
        "PyDrive==1.3.1\n",
        "pyemd==0.5.1\n",
        "pyerfa==2.0.0.1\n",
        "pyglet==1.5.0\n",
        "Pygments==2.6.1\n",
        "pygobject==3.26.1\n",
        "pymc3==3.11.4\n",
        "PyMeeus==0.5.11\n",
        "pymongo==4.0.1\n",
        "pymystem3==0.2.0\n",
        "PyOpenGL==3.1.6\n",
        "pyparsing==3.0.7\n",
        "pyrsistent==0.18.1\n",
        "pysndfile==1.3.8\n",
        "PySocks==1.7.1\n",
        "pystan==2.19.1.1\n",
        "pytest==3.6.4\n",
        "python-apt==0.0.0\n",
        "python-chess==0.23.11\n",
        "python-dateutil==2.8.2\n",
        "python-louvain==0.16\n",
        "python-slugify==6.1.0\n",
        "python-utils==3.1.0\n",
        "pytz==2018.9\n",
        "PyVirtualDisplay==3.0\n",
        "pyviz-comms==2.1.0\n",
        "PyWavelets==1.2.0\n",
        "PyYAML==3.13\n",
        "pyzmq==22.3.0\n",
        "qdldl==0.1.5.post0\n",
        "qtconsole==5.2.2\n",
        "QtPy==2.0.1\n",
        "regex==2019.12.20\n",
        "requests==2.23.0\n",
        "requests-oauthlib==1.3.1\n",
        "resampy==0.2.2\n",
        "rpy2==3.4.5\n",
        "rsa==4.8\n",
        "scikit-image==0.18.3\n",
        "scikit-learn==1.0.2\n",
        "scipy==1.4.1\n",
        "screen-resolution-extra==0.0.0\n",
        "scs==3.2.0\n",
        "seaborn==0.11.2\n",
        "semver==2.13.0\n",
        "Send2Trash==1.8.0\n",
        "setuptools-git==1.2\n",
        "Shapely==1.8.1.post1\n",
        "simplegeneric==0.8.1\n",
        "six==1.15.0\n",
        "sklearn==0.0\n",
        "sklearn-pandas==1.8.0\n",
        "smart-open==5.2.1\n",
        "snowballstemmer==2.2.0\n",
        "sortedcontainers==2.4.0\n",
        "SoundFile==0.10.3.post1\n",
        "spacy==2.2.4\n",
        "Sphinx==1.8.6\n",
        "sphinxcontrib-serializinghtml==1.1.5\n",
        "sphinxcontrib-websupport==1.2.4\n",
        "SQLAlchemy==1.4.31\n",
        "sqlparse==0.4.2\n",
        "srsly==1.0.5\n",
        "statsmodels==0.10.2\n",
        "sympy==1.7.1\n",
        "tables==3.7.0\n",
        "tabulate==0.8.9\n",
        "tblib==1.7.0\n",
        "tenacity==8.0.1\n",
        "tensorboard==2.8.0\n",
        "tensorboard-data-server==0.6.1\n",
        "tensorboard-plugin-wit==1.8.1\n",
        "tensorflow==2.7.0\n",
        "tensorflow-datasets==4.4.0\n",
        "tensorflow-estimator==2.7.0\n",
        "tensorflow-gcs-config==2.8.0\n",
        "tensorflow-hub==0.12.0\n",
        "tensorflow-io-gcs-filesystem==0.24.0\n",
        "tensorflow-metadata==1.6.0\n",
        "tensorflow-probability==0.15.0\n",
        "termcolor==1.1.0\n",
        "terminado==0.13.1\n",
        "testpath==0.6.0\n",
        "text-unidecode==1.3\n",
        "textblob==0.15.3\n",
        "Theano-PyMC==1.1.2\n",
        "thinc==7.4.0\n",
        "threadpoolctl==3.1.0\n",
        "tifffile==2021.11.2\n",
        "tomli==2.0.1\n",
        "toolz==0.11.2\n",
        "torch @ https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "torchaudio @ https://download.pytorch.org/whl/cu111/torchaudio-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "torchsummary==1.5.1\n",
        "torchtext==0.11.0\n",
        "torchvision @ https://download.pytorch.org/whl/cu111/torchvision-0.11.1%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "tornado==5.1.1\n",
        "tqdm==4.62.3\n",
        "traitlets==5.1.1\n",
        "trfl==1.2.0\n",
        "tweepy==3.10.0\n",
        "typeguard==2.7.1\n",
        "typing-extensions==3.10.0.2\n",
        "tzlocal==1.5.1\n",
        "uritemplate==3.0.1\n",
        "urllib3==1.24.3\n",
        "vega-datasets==0.9.0\n",
        "wasabi==0.9.0\n",
        "wcwidth==0.2.5\n",
        "webencodings==0.5.1\n",
        "Werkzeug==1.0.1\n",
        "widgetsnbextension==3.5.2\n",
        "wordcloud==1.5.0\n",
        "wrapt==1.13.3\n",
        "xarray==0.18.2\n",
        "xgboost==0.90\n",
        "xkit==0.0.0\n",
        "xlrd==1.1.0\n",
        "xlwt==1.3.0\n",
        "zict==2.0.0\n",
        "zipp==3.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh9qxeYDZkIL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME6O2z35ZkFV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86rFS9sVZkCO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unJDo-cFZj_E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_1zJNJWZj7t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4LesxIyK8CW"
      },
      "source": [
        "#Google Colaboratory as a convenient environment for learning about ‘reference’ (benchmark) environments of intelligent agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwfIfAn8w434"
      },
      "outputs": [],
      "source": [
        "#@title Gym package installation {form-width: \"30%\"}\n",
        "!pip install -U gym>=0.21.0\n",
        "!pip install -U gym[atari,accept-rom-license]\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "# Display packages update\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DalXMlhW6fei"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vzl3b9Ij1-6G"
      },
      "outputs": [],
      "source": [
        "#@title Gym environments querrying function {form-width: \"30%\"}\n",
        "import gym\n",
        "\n",
        "def query_environment(name):\n",
        "  env = gym.make(name)\n",
        "  spec = gym.spec(name)\n",
        "  print(f\"Action Space: {env.action_space}\")\n",
        "  print(f\"Observation Space: {env.observation_space}\")\n",
        "  print(f\"Max Episode Steps: {spec.max_episode_steps}\")\n",
        "  print(f\"Nondeterministic: {spec.nondeterministic}\")\n",
        "  print(f\"Reward Range: {env.reward_range}\")\n",
        "  print(f\"Reward Threshold: {spec.reward_threshold}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-NTOsmo5g3z"
      },
      "source": [
        "## Intelligent agent environment state visualization rendering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQcdw6aQ5zw1"
      },
      "outputs": [],
      "source": [
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Cannot find the video file\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnzLsCT32PZ3"
      },
      "source": [
        "#Observation (environment state) and action spaces of selected OpenAI Gym environments  \n",
        "## Environments types: discrete vs continuous agent action space\n",
        "\n",
        "### Mountain Car"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjyXNEqZ2taS"
      },
      "outputs": [],
      "source": [
        "query_environment(\"MountainCar-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pMbV-OKLdEe"
      },
      "outputs": [],
      "source": [
        "query_environment(\"MountainCarContinuous-v0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOkz--dIAuwC"
      },
      "source": [
        "##Joint look at the observation (environment state) space, the action space and the visualization of selected Gym environments. Usefulness of a random agent.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpxtPLAZL4-0"
      },
      "source": [
        "### Cart Pole"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lBaITkVRLcy"
      },
      "source": [
        "    Description:\n",
        "        A pole is attached by an un-actuated joint to a cart, which moves along\n",
        "        a frictionless track. The pendulum starts upright, and the goal is to\n",
        "        prevent it from falling over by increasing and reducing the cart's\n",
        "        velocity.\n",
        "    Source:\n",
        "        This environment corresponds to the version of the cart-pole problem\n",
        "        described by Barto, Sutton, and Anderson\n",
        "    Observation:\n",
        "        Type: Box(4)\n",
        "        Num     Observation               Min                     Max\n",
        "        0       Cart Position             -2.4                    2.4\n",
        "        1       Cart Velocity             -Inf                    Inf\n",
        "        2       Pole Angle                -0.209 rad (-12 deg)    0.209 rad (12 deg)\n",
        "        3       Pole Angular Velocity     -Inf                    Inf\n",
        "    Actions:\n",
        "        Type: Discrete(2)\n",
        "        Num   Action\n",
        "        0     Push cart to the left\n",
        "        1     Push cart to the right\n",
        "        Note: The amount the velocity that is reduced or increased is not\n",
        "        fixed; it depends on the angle the pole is pointing. This is because\n",
        "        the center of gravity of the pole increases the amount of energy needed\n",
        "        to move the cart underneath it\n",
        "    Reward:\n",
        "        Reward is 1 for every step taken, including the termination step\n",
        "    Starting State:\n",
        "        All observations are assigned a uniform random value in [-0.05..0.05]\n",
        "    Episode Termination:\n",
        "        Pole Angle is more than 12 degrees.\n",
        "        Cart Position is more than 2.4 (center of the cart reaches the edge of\n",
        "        the display).\n",
        "        Episode length is greater than 200.\n",
        "        Solved Requirements:\n",
        "        Considered solved when the average return is greater than or equal to\n",
        "        195.0 over 100 consecutive trials.\n",
        "\n",
        "\n",
        "[https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOOSTr1K3vsY"
      },
      "outputs": [],
      "source": [
        "query_environment(\"CartPole-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM5FQb8VBSue"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True: \n",
        "    env.render()\n",
        "    action = env.action_space.sample()   \n",
        "    observation, reward, done, info = env.step(action)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H6DahZH3wKS"
      },
      "source": [
        "### Atari Atlantis-v0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgnQk-962n71"
      },
      "outputs": [],
      "source": [
        "query_environment(\"Atlantis-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuqUQcOy6pL5"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"Atlantis-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True: \n",
        "    env.render()\n",
        "    action = env.action_space.sample()        \n",
        "    observation, reward, done, info = env.step(action)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7lL5OfmCl1q"
      },
      "outputs": [],
      "source": [
        "query_environment(\"MsPacman-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oihV0EUxFK4U"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"MsPacman-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True: \n",
        "    env.render()   \n",
        "    action = env.action_space.sample()        \n",
        "    observation, reward, done, info = env.step(action)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9_AmoBqIPUG"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"Acrobot-v1\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True: \n",
        "    env.render()   \n",
        "    action = env.action_space.sample()        \n",
        "    observation, reward, done, info = env.step(action)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6Vrym-7IQEN"
      },
      "outputs": [],
      "source": [
        "#env = wrap_env(gym.make(\"Pendulum-v1\"))\n",
        "env = wrap_env(gym.make(\"Pendulum-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True: \n",
        "    env.render()   \n",
        "    action = env.action_space.sample()        \n",
        "    observation, reward, done, info = env.step(action)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mindjNPKkfP_"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"BattleZone-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True: \n",
        "    env.render()   \n",
        "    action = env.action_space.sample()        \n",
        "    observation, reward, done, info = env.step(action)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUh6gYQNN3lK"
      },
      "source": [
        "##A random agent, a hard-coded rule-based agent and a reinforcement learning agent in **exactly the same** benchmark environment (\"CartPole-v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DX7pOfdOpap"
      },
      "source": [
        "###Random agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHi9zzMQE_o3"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "    # Uruchomienie agenta\n",
        "    action = env.action_space.sample() \n",
        "    observation, reward, done, info = env.step(action)     \n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "#for episode in range(10): \n",
        "    #obs = env.reset()\n",
        "    #for step in range(50):\n",
        "        #print(obs)\n",
        "        #action = env.action_space.sample()  # or given a custom model, action = policy(observation)\n",
        "        #nobs, reward, done, info = env.step(action)\n",
        "        #if done:\n",
        "            #print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "            #break\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1bPvtSxO3O_"
      },
      "source": [
        "### Rule-based agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBqEmdVuRTeD"
      },
      "outputs": [],
      "source": [
        "query_environment(\"CartPole-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-214wrjxO-w5"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "state = env.reset()\n",
        "state_history = []\n",
        "masked_state_history = []\n",
        "action_history = []\n",
        "reward_history = []\n",
        "error_history = []\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "    state_history.append(state)\n",
        "    masked_state = state[2]\n",
        "    masked_state_history.append(masked_state)\n",
        "    error = masked_state # Why is it so simple?\n",
        "    error_history.append(error)\n",
        "    prev_error = error\n",
        "    if error> 0:\n",
        "      action = 1\n",
        "    else:\n",
        "      action = 0\n",
        "    action_history.append(action)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    reward_history.append(reward)\n",
        "    state_history.append(state)\n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMup6GA3V34y"
      },
      "source": [
        "###Reinforcement learning (DQN) agent ('educational naive do-it-yourself implementation' -> 'very-slowly-agent-training implementation'!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEE3yyfgttxY"
      },
      "outputs": [],
      "source": [
        "!apt update && apt install -y libpq-dev libsdl2-dev swig xorg-dev xvfb python-opengl\n",
        "!pip install --upgrade pip\n",
        "\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install tf-agents pyvirtualdisplay\n",
        "!pip install gym>=0.21.0\n",
        "!pip install gym[box2d,atari,accept-rom-license]\n",
        "!pip install piglet\n",
        "\n",
        "!pip install dm-acme==0.3.0\"\n",
        "!pip install dm-acme[reverb]==0.3.0\"\n",
        "!pip install dm-acme[tf]==0.3.0\"\n",
        "!pip install dm-acme[envs]==0.3.0\"\n",
        "!pip install dm-env\n",
        "\n",
        "#from IPython.display import clear_output\n",
        "#clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "145o8iNituUm"
      },
      "outputs": [],
      "source": [
        "!pip install -U tensorflow==2.7.0\n",
        "!pip install dm-reverb\n",
        "!pip install numpy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "223Rxd6z8xZy"
      },
      "outputs": [],
      "source": [
        "!pip install dm-acme==\"0.3.0\"\n",
        "!pip install dm-acme[reverb]==\"0.3.0\"\n",
        "!pip install dm-acme[tf]==\"0.3.0\"\n",
        "!pip install dm-acme[envs]==\"0.3.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgSpmYENt9WQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8bmEYvOztur"
      },
      "outputs": [],
      "source": [
        "#!pip install acme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5xvDjU6HpFK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import gym\n",
        "import pyvirtualdisplay\n",
        "\n",
        "import acme\n",
        "from acme.agents.tf import dqn\n",
        "from acme.utils import loggers\n",
        "from acme import wrappers\n",
        "from acme import specs\n",
        "import sonnet as snt\n",
        "import dm_env\n",
        "import enum\n",
        "import pandas as pd\n",
        "import time\n",
        "import imageio\n",
        "import base64\n",
        "\n",
        "from typing import Callable, Optional, Sequence\n",
        "\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "\n",
        "def update_scene(num, frames, patch):\n",
        "    patch.set_data(frames[num])\n",
        "    return patch,\n",
        "\n",
        "def plot_animation(frames, repeat=False, interval=40):\n",
        "    fig = plt.figure()\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "    anim = animation.FuncAnimation(\n",
        "        fig, update_scene, fargs=(frames, patch),\n",
        "        frames=len(frames), repeat=repeat, interval=interval)\n",
        "    plt.close()\n",
        "    return anim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SW8Gs6Yuolg"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "#tf.random.set_seed(42)\n",
        "#np.random.seed(42)\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "input_shape = [4] # == env.observation_space.shape\n",
        "n_outputs = 2 # == env.action_space.n\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(32, activation=\"elu\", input_shape=input_shape),\n",
        "    keras.layers.Dense(32, activation=\"elu\"),\n",
        "    keras.layers.Dense(n_outputs)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtU3K0NtvrzA"
      },
      "outputs": [],
      "source": [
        "def epsilon_greedy_policy(state, epsilon=0):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return np.random.randint(n_outputs)\n",
        "    else:\n",
        "        Q_values = model.predict(state[np.newaxis])\n",
        "        return np.argmax(Q_values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLeimqFLvrzA"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "replay_memory = deque(maxlen=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arAFnos1vrzB"
      },
      "outputs": [],
      "source": [
        "def sample_experiences(batch_size):\n",
        "    indices = np.random.randint(len(replay_memory), size=batch_size)\n",
        "    batch = [replay_memory[index] for index in indices]\n",
        "    states, actions, rewards, next_states, dones = [\n",
        "        np.array([experience[field_index] for experience in batch])\n",
        "        for field_index in range(5)]\n",
        "    return states, actions, rewards, next_states, dones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nksczGHvrzB"
      },
      "outputs": [],
      "source": [
        "def play_one_step(env, state, epsilon):\n",
        "    action = epsilon_greedy_policy(state, epsilon)\n",
        "    next_state, reward, done, info = env.step(action)\n",
        "    replay_memory.append((state, action, reward, next_state, done))\n",
        "    return next_state, reward, done, info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H-z8gD5vrzC"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "discount_rate = 0.95\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
        "loss_fn = keras.losses.mean_squared_error\n",
        "\n",
        "def training_step(batch_size):\n",
        "    experiences = sample_experiences(batch_size)\n",
        "    states, actions, rewards, next_states, dones = experiences\n",
        "    next_Q_values = model.predict(next_states)\n",
        "    max_next_Q_values = np.max(next_Q_values, axis=1)\n",
        "    target_Q_values = (rewards + (1 - dones) * discount_rate * max_next_Q_values)\n",
        "    target_Q_values = target_Q_values.reshape(-1, 1)\n",
        "    mask = tf.one_hot(actions, n_outputs)\n",
        "    with tf.GradientTape() as tape:\n",
        "        all_Q_values = model(states)\n",
        "        Q_values = tf.reduce_sum(all_Q_values * mask, axis=1, keepdims=True)\n",
        "        loss = tf.reduce_mean(loss_fn(target_Q_values, Q_values))\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWv9mO7vvrzD"
      },
      "outputs": [],
      "source": [
        "#env.seed(42)\n",
        "#np.random.seed(42)\n",
        "#tf.random.set_seed(42)\n",
        "\n",
        "rewards = [] \n",
        "best_score = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKJOpMmUvrzD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#for episode in range(10000): \n",
        "for episode in range(100): #ridiculously low number\n",
        "    obs = env.reset()    \n",
        "    for step in range(200): #ridiculously low number (as for the v1 version of Cartpole)\n",
        "        epsilon = max(1 - episode / 500, 0.01)\n",
        "        obs, reward, done, info = play_one_step(env, obs, epsilon)\n",
        "        if done:\n",
        "            break\n",
        "    rewards.append(step)\n",
        "    if step >= best_score:\n",
        "        best_weights = model.get_weights()\n",
        "        best_score = step\n",
        "    print(\"\\rEpisode: {}, Steps: {}, eps: {:.3f}\".format(episode, step + 1, epsilon), end=\"\")\n",
        "    if episode > 50:\n",
        "        training_step(batch_size)\n",
        "\n",
        "model.set_weights(best_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pzQ7f7GXykg"
      },
      "source": [
        "<a name=\"CartPole-Keras-wykres\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USTgx-XQvrzD"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(rewards)\n",
        "plt.xlabel(\"Episode\", fontsize=14)\n",
        "plt.ylabel(\"Sum of rewards\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fhQB4jiX61n"
      },
      "source": [
        "<a name=\"CartPole-Keras-film\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQI0_nG5WerM"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "#environment_train = gym_wrapper.GymWrapper(gym.make('CartPole-v0'))\n",
        "#environment_train = wrappers.SinglePrecisionWrapper(environment_train)\n",
        "#environment = gym_wrapper.GymWrapper(gym.make('CartPole-v0'))\n",
        "#environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "#environment.env.theta_threshold_radians = 10.0\n",
        "\n",
        "#env.seed(42)\n",
        "observation = env.reset()\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "    #action = env.action_space.sample()\n",
        "    action = epsilon_greedy_policy(observation)\n",
        "    observation, reward, done, info = env.step(action)     \n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "#for episode in range(10): \n",
        "    #obs = env.reset()\n",
        "    #for step in range(50):\n",
        "        #print(obs)\n",
        "        #action = env.action_space.sample()  # or given a custom model, action = policy(observation)\n",
        "        #nobs, reward, done, info = env.step(action)\n",
        "        #if done:\n",
        "            #print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "            #break\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_tLwNGHWg9C"
      },
      "source": [
        "#Looking deeper into OpenAI Gym ‘reference’ (benchmark) environments states dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrzfC5ZXFz29"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"MountainCarContinuous-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True:\n",
        "    env.render() \n",
        "    action = env.action_space.sample()      \n",
        "    observation, reward, done, info = env.step(action)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-7apnKf6B2P"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"MountainCarContinuous-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "observations_history = []\n",
        "actions_history = []\n",
        "\n",
        "while True:\n",
        "    env.render() \n",
        "    action = env.action_space.sample()\n",
        "    actions_history.append(action)      \n",
        "    observation, reward, done, info = env.step(action)\n",
        "    observations_history.append(observation)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_m0qTTh51FT"
      },
      "outputs": [],
      "source": [
        "print(len(observations_history))\n",
        "print(observations_history[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPBoiAj9884U"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaumxKta9F9b"
      },
      "outputs": [],
      "source": [
        "plt.plot(observations_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p6QxJuI9YpD"
      },
      "outputs": [],
      "source": [
        "plt.plot(actions_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHSnZnKD7aaL"
      },
      "outputs": [],
      "source": [
        "env.action_space.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEIPzmHU7_KH"
      },
      "outputs": [],
      "source": [
        "env_action_space_sample = env.action_space.sample()\n",
        "env_action_space_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLj4LX9j8S7t"
      },
      "outputs": [],
      "source": [
        "env_action_space_sample[0] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvcKMK8W6vGq"
      },
      "outputs": [],
      "source": [
        "#env = wrap_env(gym.make(\"MountainCarContinuous-v0\"))\n",
        "\n",
        "#env = wrap_env(gym.make(\"MountainCarContinuous-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "observations_history = []\n",
        "actions_history = []\n",
        "\n",
        "while True:\n",
        "    env.render() \n",
        "    #action = env.action_space.sample()\n",
        "    action = env_action_space_sample\n",
        "    actions_history.append(action)      \n",
        "    observation, reward, done, info = env.step(action)\n",
        "    observations_history.append(observation)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQRB0n4g6WwX"
      },
      "outputs": [],
      "source": [
        "env_action_space_sample[0] = -1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmBTyrB98zq2"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"MountainCarContinuous-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "observations_history = []\n",
        "\n",
        "while True:\n",
        "    env.render() \n",
        "    #action = env.action_space.sample()\n",
        "    action = env_action_space_sample\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    observations_history.append(observation)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XumYyTOt8z0F"
      },
      "outputs": [],
      "source": [
        "plt.plot(observations_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7RHasQ4AyfB"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS0JcLVvAQrD"
      },
      "outputs": [],
      "source": [
        "observations_history_as_array = np.array(observations_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mG3C2DNA3pj"
      },
      "outputs": [],
      "source": [
        "plt.plot(observations_history_as_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lsLiLWVA8Bq"
      },
      "outputs": [],
      "source": [
        "plt.plot(observations_history_as_array[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-576W8__Shf"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"MountainCarContinuous-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "observations_history = []\n",
        "actions_history = []\n",
        "\n",
        "while True:\n",
        "    env.render() \n",
        "    if len(observations_history) == 0:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      if observation[1] > 0:\n",
        "        action_value = 1.0\n",
        "      else:\n",
        "        action_value = -1.0\n",
        "      env_action_space_sample[0] = action_value\n",
        "      action = env_action_space_sample\n",
        "    actions_history.append(action)      \n",
        "    observation, reward, done, info = env.step(action)\n",
        "    observations_history.append(observation)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh_rQERh_SkG"
      },
      "outputs": [],
      "source": [
        "plt.plot(actions_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MU0kBjx_Snc"
      },
      "outputs": [],
      "source": [
        "plt.plot(observations_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAiuEWpD_Sq1"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"MountainCarContinuous-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "observations_history = []\n",
        "actions_history = []\n",
        "\n",
        "while True:\n",
        "    env.render() \n",
        "    if len(observations_history) == 0:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      if observation[0] > 0:\n",
        "        action_value = 1.0\n",
        "      else:\n",
        "        action_value = -1.0\n",
        "      env_action_space_sample[0] = action_value\n",
        "      action = env_action_space_sample\n",
        "    actions_history.append(action)      \n",
        "    observation, reward, done, info = env.step(action)\n",
        "    observations_history.append(observation)       \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6Gpt1XcEKyr"
      },
      "outputs": [],
      "source": [
        "plt.plot(actions_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgJEnLQrHaqg"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CmVBwIJHau6"
      },
      "source": [
        "#OpenAI Gym and simple control theory problem solving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUMKIlQoOdLS"
      },
      "source": [
        "##“Classic” reinforcement learning agent (the agent trained earlier, based on the poor, naive implementation of DQN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE937zQ4ObT_"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "#environment_train = gym_wrapper.GymWrapper(gym.make('CartPole-v0'))\n",
        "#environment_train = wrappers.SinglePrecisionWrapper(environment_train)\n",
        "#environment = gym_wrapper.GymWrapper(gym.make('CartPole-v0'))\n",
        "#environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "#environment.env.theta_threshold_radians = 10.0\n",
        "\n",
        "#env.seed(42)\n",
        "observation = env.reset()\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "    #action = env.action_space.sample()\n",
        "    action = epsilon_greedy_policy(observation)\n",
        "    observation, reward, done, info = env.step(action)     \n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "#for episode in range(10): \n",
        "    #obs = env.reset()\n",
        "    #for step in range(50):\n",
        "        #print(obs)\n",
        "        #action = env.action_space.sample()  # or given a custom model, action = policy(observation)\n",
        "        #nobs, reward, done, info = env.step(action)\n",
        "        #if done:\n",
        "            #print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "            #break\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAkw7x_9O7A0"
      },
      "source": [
        "##“Classic” control-theoretic agent: hard-coded (non-trainable, manually tunable) agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B23V516JFeZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgk2ryMyF2eG"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "desired_state = np.array([0, 0, 0, 0])\n",
        "desired_mask = np.array([0, 0, 1, 0])\n",
        "\n",
        "P, I, D = 0.02, 0.01, 0.5\n",
        "\n",
        "state = env.reset()\n",
        "integral = 0\n",
        "derivative = 0\n",
        "prev_error = 0\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "\n",
        "    error = state - desired_state\n",
        "\n",
        "    integral += error\n",
        "    derivative = error - prev_error\n",
        "    prev_error = error\n",
        "\n",
        "    pid = np.dot(P * error + I * integral + D * derivative, desired_mask)\n",
        "    action = sigmoid(pid)\n",
        "    action = np.round(action).astype(np.int32)\n",
        "\n",
        "    state, reward, done, info = env.step(action)\n",
        "\n",
        "\n",
        "    # Uruchomienie agenta\n",
        "#    action = env.action_space.sample() \n",
        "#    observation, reward, done, info = env.step(action)     \n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ydpHuqxF6cR"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "states_history = []\n",
        "actions_history = []\n",
        "\n",
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "desired_state = np.array([0, 0, 0, 0])\n",
        "desired_mask = np.array([0, 0, 1, 0])\n",
        "\n",
        "#P, I, D = 0.05, 0.02, 0.6\n",
        "P, I, D = 0.02, 0.01, 0.5\n",
        "\n",
        "state = env.reset()\n",
        "integral = 0\n",
        "derivative = 0\n",
        "prev_error = 0\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "\n",
        "    error = state - desired_state\n",
        "\n",
        "    integral += error\n",
        "    derivative = error - prev_error\n",
        "    prev_error = error\n",
        "\n",
        "    pid = np.dot(P * error + I * integral + D * derivative, desired_mask)\n",
        "    action = sigmoid(pid)\n",
        "    action = np.round(action).astype(np.int32)\n",
        "\n",
        "    state, reward, done, info = env.step(action)\n",
        "\n",
        "    states_history.append(state)\n",
        "    actions_history.append(action)\n",
        "\n",
        "\n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wUUjn_mJaaC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jABhV1pF6fM"
      },
      "outputs": [],
      "source": [
        "plt.plot(actions_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0w-0XuvYq7j"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ymBD8kGYq7l"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "desired_state = np.array([0, 0, 0, 0])\n",
        "desired_mask = np.array([0, 0, 1, 0])\n",
        "\n",
        "P, I, D = 0.02, 0.01, 0.5\n",
        "\n",
        "state = env.reset()\n",
        "integral = 0\n",
        "derivative = 0\n",
        "prev_error = 0\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "\n",
        "    error = state - desired_state\n",
        "\n",
        "    integral += error\n",
        "    derivative = error - prev_error\n",
        "    prev_error = error\n",
        "\n",
        "    pid = np.dot(P * error + I * integral + D * derivative, desired_mask)\n",
        "    action = sigmoid(pid)\n",
        "    action = np.round(action).astype(np.int32)\n",
        "\n",
        "    state, reward, done, info = env.step(action)\n",
        "\n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xusJbuh5Yq7q"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "states_history = []\n",
        "actions_history = []\n",
        "\n",
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "desired_state = np.array([0, 0, 0, 0])\n",
        "desired_mask = np.array([0, 0, 1, 0])\n",
        "\n",
        "#P, I, D = 0.05, 0.02, 0.6\n",
        "P, I, D = 0.02, 0.01, 0.5\n",
        "\n",
        "state = env.reset()\n",
        "integral = 0\n",
        "derivative = 0\n",
        "prev_error = 0\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "\n",
        "    error = state - desired_state\n",
        "\n",
        "    integral += error\n",
        "    derivative = error - prev_error\n",
        "    prev_error = error\n",
        "\n",
        "    pid = np.dot(P * error + I * integral + D * derivative, desired_mask)\n",
        "    action = sigmoid(pid)\n",
        "    action = np.round(action).astype(np.int32)\n",
        "\n",
        "    state, reward, done, info = env.step(action)\n",
        "\n",
        "    states_history.append(state)\n",
        "    actions_history.append(action)\n",
        "\n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GETg9GRRlQVB"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "#env.env.reward_threshold = 0.000000001\n",
        "#env.theta_threshold_radians = 30\n",
        "\n",
        "desired_state = np.array([0, 0, 0, 0])\n",
        "masked_desired_state = 1.0\n",
        "desired_mask = np.array([0, 0, 1, 0])\n",
        "\n",
        "P, I, D = 0.02, 0.01, 0.5\n",
        "\n",
        "state = env.reset()\n",
        "integral = 0\n",
        "masked_integral = 0\n",
        "quasimasked_integral = 0\n",
        "derivative = 0\n",
        "prev_error = 0\n",
        "masked_prev_error = 0\n",
        "quasimasked_prev_error = 0\n",
        "pid_history = []\n",
        "state_history = []\n",
        "masked_state_history = []\n",
        "action_history = []\n",
        "reward_history = []\n",
        "masked_pid_history = []\n",
        "error_history = []\n",
        "masked_error_history = []\n",
        "quasimasked_error_history = []\n",
        "quasimasked_pid_history = []\n",
        "\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "\n",
        "    error = state - desired_state\n",
        "    masked_state = np.dot(state, desired_mask)\n",
        "    #masked_error = masked_state - masked_desired_state\n",
        "    masked_error = masked_state\n",
        "\n",
        "    error_history.append(error)\n",
        "    quasimasked_error = np.dot(error, desired_mask)\n",
        "    quasimasked_error_history.append(quasimasked_error)\n",
        "    masked_error_history.append(masked_error)\n",
        "\n",
        "\n",
        "    masked_state = np.dot(state, desired_mask)\n",
        "\n",
        "\n",
        "    integral += error\n",
        "    masked_integral += masked_error\n",
        "    quasimasked_integral += quasimasked_error\n",
        "    derivative = error - prev_error\n",
        "    masked_derivative = masked_error - masked_prev_error\n",
        "    quasimasked_derivative = quasimasked_error - quasimasked_prev_error\n",
        "    prev_error = error\n",
        "    masked_prev_error = masked_error\n",
        "\n",
        "    #pid = np.dot(P * error + I * integral + D * derivative, desired_mask)\n",
        "    pid = np.dot(P * error + I * integral + D * derivative, desired_mask)\n",
        "    masked_pid = P * masked_error + I * masked_integral + D * masked_derivative\n",
        "    pid = P * masked_error + I * masked_integral + D * masked_derivative\n",
        "    quasimasked_pid = P * quasimasked_error + I * quasimasked_integral + D * quasimasked_derivative\n",
        "    pid_history.append(pid)\n",
        "    masked_pid_history.append(masked_pid)\n",
        "    quasimasked_pid_history.append(quasimasked_pid)\n",
        "    action = sigmoid(pid)\n",
        "    action = np.round(action).astype(np.int32)\n",
        "\n",
        "    action_history.append(action)\n",
        "\n",
        "    state, reward, done, info = env.step(action)\n",
        "    reward_history.append(reward)\n",
        "    state_history.append(state)\n",
        "    masked_state_history.append(masked_state)\n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45KbK5xI3hmx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YI5_3w6zDk4"
      },
      "outputs": [],
      "source": [
        "plt.plot(quasimasked_pid_history)\n",
        "#plt.plot(masked_pid_history)\n",
        "plt.plot(pid_history)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34JTY-s3MasL"
      },
      "outputs": [],
      "source": [
        "plt.plot(quasimasked_error_history)\n",
        "plt.plot(masked_error_history)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spzrTGQZMqeM"
      },
      "outputs": [],
      "source": [
        "#plt.plot(quasimasked_error_history)\n",
        "plt.plot(masked_error_history)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xV6dX0nM2gs"
      },
      "outputs": [],
      "source": [
        "masked_error_history_shifted = list(np.array(masked_error_history) + 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZVpIhlCNEOo"
      },
      "outputs": [],
      "source": [
        "plt.plot(masked_error_history_shifted, label=\"masked_error_history_shifted\")\n",
        "plt.plot(masked_error_history, label=\"masked_error_history\")\n",
        "#plt.plot(quasimasked_error_history, label=\"quasimasked_error_history\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu211ixMy14f"
      },
      "outputs": [],
      "source": [
        "#plt.plot(reward_history)\n",
        "plt.plot(masked_state_history)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65508oyzp5oc"
      },
      "outputs": [],
      "source": [
        "print(masked_state_history[-1])\n",
        "print(state_history[-1][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJxWnngDuSyg"
      },
      "outputs": [],
      "source": [
        "error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7xs8xkJpAWc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omTkTr4WojUZ"
      },
      "outputs": [],
      "source": [
        "plt.plot(pid_history)\n",
        "plt.plot(masked_state_history)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvJxVHPPo5gi"
      },
      "outputs": [],
      "source": [
        "min(pid_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi2hP1emo5jt"
      },
      "outputs": [],
      "source": [
        "max(pid_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rls4VZZ8wzW9"
      },
      "outputs": [],
      "source": [
        "max(pid_history)-min(pid_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4EG9urNwgXq"
      },
      "outputs": [],
      "source": [
        "temp_step_size = (max(pid_history)-min(pid_history))/100.0\n",
        "temp_step_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYEmfJOKo5nA"
      },
      "outputs": [],
      "source": [
        "#np.arange(min(pid_history), max(pid_history), temp_step_size)\n",
        "temp_sigmoid_domain = np.arange(min(pid_history), max(pid_history), (max(pid_history)-min(pid_history))/100.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlMhJb78v5DP"
      },
      "outputs": [],
      "source": [
        "temp_sigmoid_values = sigmoid(temp_sigmoid_domain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0s-c1VCv5Fo"
      },
      "outputs": [],
      "source": [
        "plt.plot(temp_sigmoid_domain,temp_sigmoid_values)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJocJd6Wv5H9"
      },
      "outputs": [],
      "source": [
        "temp_sigmoid_domain = np.arange(min(pid_history)*1000, max(pid_history)*1000, (max(pid_history)*1000-min(pid_history)*1000)/1000.0)\n",
        "temp_sigmoid_values = sigmoid(temp_sigmoid_domain)\n",
        "plt.plot(temp_sigmoid_domain,temp_sigmoid_values)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVfjEfchViyi"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "masked_state_history = []\n",
        "\n",
        "observation = env.reset()\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "    action = env.action_space.sample() \n",
        "    state, reward, done, info = env.step(action)\n",
        "    masked_state = state[2]\n",
        "    masked_state_history.append(masked_state)\n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "#for episode in range(10): \n",
        "    #obs = env.reset()\n",
        "    #for step in range(50):\n",
        "        #print(obs)\n",
        "        #action = env.action_space.sample()  # or given a custom model, action = policy(observation)\n",
        "        #nobs, reward, done, info = env.step(action)\n",
        "        #if done:\n",
        "            #print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "            #break\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wiP97l1WXYZ"
      },
      "outputs": [],
      "source": [
        "plt.plot(masked_state_history)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5My8_CkxiBQ"
      },
      "outputs": [],
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "P, I, D = 0.02, 0.01, 0.5\n",
        "\n",
        "state = env.reset()\n",
        "integral = 0\n",
        "derivative = 0\n",
        "prev_error = 0\n",
        "pid_history = []\n",
        "state_history = []\n",
        "masked_state_history = []\n",
        "action_history = []\n",
        "reward_history = []\n",
        "masked_pid_history = []\n",
        "error_history = []\n",
        "\n",
        "while True:  \n",
        "    env.render()\n",
        "    state_history.append(state)\n",
        "    masked_state = state[2]\n",
        "    masked_state_history.append(masked_state)\n",
        "    error = masked_state # Why is it so simple?\n",
        "    error_history.append(error)\n",
        "    integral += error\n",
        "    derivative = error - prev_error\n",
        "    prev_error = error\n",
        "    pid = P * error + I * integral + D * derivative\n",
        "    pid_history.append(pid)\n",
        "    action = sigmoid(pid)\n",
        "    action = np.round(action).astype(np.int32)\n",
        "    action_history.append(action)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    reward_history.append(reward)\n",
        "    state_history.append(state)\n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Yp-iwv25wn"
      },
      "source": [
        "#Differences between the popular environment-agent APIs: OpenAI Gym vs DeepMind Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1sMtaZ-ZELr"
      },
      "outputs": [],
      "source": [
        "!pip install dm-acme==0.3.0\n",
        "!pip install dm-acme[reverb]==0.3.0\n",
        "!pip install dm-acme[tf]==0.3.0\n",
        "!pip install dm-acme[envs]==0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRHLFzqX7qpK"
      },
      "outputs": [],
      "source": [
        "#@title Install requirements  { form-width: \"30%\" }\n",
        "\n",
        "!pip install dm-env\n",
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "!pip install imageio\n",
        "\n",
        "#rom IPython.display import clear_output\n",
        "#clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGbHKf2QpMnL"
      },
      "outputs": [],
      "source": [
        "#@title Install necessary dependencies.\n",
        "\n",
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "#!pip install 'gym==0.10.11'\n",
        "!pip install gym\n",
        "!pip install imageio\n",
        "!pip install PILLOW\n",
        "#!pip install 'pyglet==1.3.2'\n",
        "!pip install pyglet\n",
        "!pip install pyvirtualdisplay\n",
        "\n",
        "#!pip install dm-acme\n",
        "#!pip install dm-acme[reverb]\n",
        "#!pip install dm-acme[tf]\n",
        "#!pip install dm-acme[envs]\n",
        "\n",
        "#from IPython.display import clear_output\n",
        "#clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OGqsOuw1Yk1"
      },
      "outputs": [],
      "source": [
        "!pip install dm-acme==0.3.0\n",
        "!pip install dm-acme[reverb]==0.3.0\n",
        "!pip install dm-acme[tf]==0.3.0\n",
        "!pip install dm-acme[envs]==0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt6UYSfIoMAQ"
      },
      "outputs": [],
      "source": [
        "#@title Import modules.\n",
        "#python3\n",
        "\n",
        "%%capture\n",
        "import copy\n",
        "import pyvirtualdisplay\n",
        "import imageio \n",
        "import base64\n",
        "import IPython\n",
        "\n",
        "from acme import environment_loop\n",
        "from acme.tf import networks\n",
        "from acme.adders import reverb as adders\n",
        "from acme.agents.tf import actors as actors\n",
        "from acme.datasets import reverb as datasets\n",
        "from acme.wrappers import gym_wrapper\n",
        "from acme import specs\n",
        "from acme import wrappers\n",
        "from acme.agents.tf import d4pg\n",
        "from acme.agents import agent\n",
        "from acme.tf import utils as tf2_utils\n",
        "from acme.utils import loggers\n",
        "\n",
        "import gym \n",
        "import dm_env\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import reverb\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set up a virtual display for rendering OpenAI gym environments.\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VEH-x_i7ujM"
      },
      "outputs": [],
      "source": [
        "#@title Import modules  { form-width: \"30%\" }\n",
        "\n",
        "import IPython\n",
        "from typing import Callable, Optional, Sequence\n",
        "\n",
        "import acme\n",
        "from acme import environment_loop\n",
        "from acme import specs\n",
        "from acme import wrappers\n",
        "from acme.utils import tree_utils\n",
        "from acme.agents.tf import dqn\n",
        "# from acme.utils import counting\n",
        "from acme.utils import loggers\n",
        "import base64\n",
        "import collections\n",
        "import dm_env\n",
        "import enum\n",
        "# import functools\n",
        "import gym\n",
        "# import io\n",
        "import imageio\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sonnet as snt\n",
        "import tensorflow.compat.v2 as tf\n",
        "tf.enable_v2_behavior()\n",
        "import tensorflow_probability as tfp\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=1)\n",
        "\n",
        "plt.style.use('seaborn-notebook')\n",
        "plt.style.use('seaborn-whitegrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl9FUFLauUZF"
      },
      "source": [
        "### Acme agent interface (from \"RL MLSS Tutorial\" [https://colab.research.google.com/github/feryal/rl_mlss_2020/blob/master/RL_Tutorial_MLSS_2020.ipynb])\n",
        "\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?id=1T7FTpA9RgDYFkciDFZK4brNyURZN_ZGp\" width=\"500\" /></center>\n",
        "\n",
        "Each agent implements the following functions:\n",
        "\n",
        "```python\n",
        "class Agent(acme.Actor):\n",
        "  def __init__(self, number_of_actions, number_of_states, ...):\n",
        "    \"\"\"Provides the agent the number of actions and number of states.\"\"\"\n",
        "\n",
        "  def select_action(self, observation):\n",
        "    \"\"\"Generates actions from observations.\"\"\"\n",
        "\n",
        "  def observe_first(self, timestep):\n",
        "    \"\"\"Records the initial timestep in a trajectory.\"\"\"\n",
        "  \n",
        "  def observe(self, action, next_timestep):\n",
        "    \"\"\"Records the transition which occurred from taking an action.\"\"\"\n",
        "\n",
        "  def update(self):\n",
        "    \"\"\"Updates the agent's internals to potentially change its behavior.\"\"\"\n",
        "```\n",
        "\n",
        "For now just one remark on the `observe()` function: In the last method, the `next_timestep` provides the `reward`, `discount`, and `observation` that resulted from selecting `action`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O7FWlEo8w9L"
      },
      "outputs": [],
      "source": [
        "#@title Implement the run loop  { form-width: \"30%\" }\n",
        "\n",
        "def run_loop(\n",
        "    environment: dm_env.Environment,\n",
        "    agent: acme.Actor,\n",
        "    num_episodes: Optional[int] = None,\n",
        "    num_steps: Optional[int] = None,\n",
        "    logger_time_delta: float = .25,\n",
        "    label: str = 'training_loop',\n",
        "    log_loss: bool = False,\n",
        "):\n",
        "  \"\"\"Perform the run loop.\n",
        "\n",
        "  We are following the Acme run loop.\n",
        "\n",
        "  Run the environment loop for `num_episodes` episodes. Each episode is itself\n",
        "  a loop which interacts first with the environment to get an observation and\n",
        "  then give that observation to the agent in order to retrieve an action. Upon\n",
        "  termination of an episode a new episode will be started. If the number of\n",
        "  episodes is not given then this will interact with the environment\n",
        "  infinitely.\n",
        "\n",
        "  Args:\n",
        "    environment: dm_env.Environment used to generate trajectories.\n",
        "    agent: acme.Actor for selecting actions in the run loop.\n",
        "    num_steps: number of steps to run the loop for. If `None` (default), runs\n",
        "      without limit.\n",
        "    num_episodes: number of episodes to run the loop for. If `None` (default),\n",
        "      runs without limit.\n",
        "    logger_time_delta: time interval (in seconds) between consecutive logging\n",
        "      steps.\n",
        "    label: optional label used at logging steps.\n",
        "  \"\"\"\n",
        "  logger = loggers.TerminalLogger(label=label, time_delta=logger_time_delta)\n",
        "  iterator = range(num_episodes) if num_episodes else itertools.count()\n",
        "  all_returns = []\n",
        "  \n",
        "  num_total_steps = 0\n",
        "  for episode in iterator:\n",
        "    # Reset any counts and start the environment.\n",
        "    start_time = time.time()\n",
        "    episode_steps = 0\n",
        "    episode_return = 0\n",
        "    episode_loss = 0\n",
        "\n",
        "    timestep = environment.reset()\n",
        "    \n",
        "    # Make the first observation.\n",
        "    agent.observe_first(timestep)\n",
        "\n",
        "    # Run an episode.\n",
        "    while not timestep.last():\n",
        "      # Generate an action from the agent's policy and step the environment.\n",
        "      action = agent.select_action(timestep.observation)\n",
        "      timestep = environment.step(action)\n",
        "\n",
        "      # Have the agent observe the timestep and let the agent update itself.\n",
        "      agent.observe(action, next_timestep=timestep)\n",
        "      agent.update()\n",
        "\n",
        "      # Book-keeping.\n",
        "      episode_steps += 1\n",
        "      num_total_steps += 1\n",
        "      episode_return += timestep.reward\n",
        "\n",
        "      if log_loss:\n",
        "        episode_loss += agent.last_loss\n",
        "\n",
        "      if num_steps is not None and num_total_steps >= num_steps:\n",
        "        break\n",
        "\n",
        "    # Collect the results and combine with counts.\n",
        "    steps_per_second = episode_steps / (time.time() - start_time)\n",
        "    result = {\n",
        "        'episode': episode,\n",
        "        'episode_length': episode_steps,\n",
        "        'episode_return': episode_return,\n",
        "    }\n",
        "    if log_loss:\n",
        "      result['loss_avg'] = episode_loss / episode_steps\n",
        "\n",
        "    all_returns.append(episode_return)\n",
        "\n",
        "    # Log the given results.\n",
        "    logger.write(result)\n",
        "    \n",
        "    if num_steps is not None and num_total_steps >= num_steps:\n",
        "      break\n",
        "\n",
        "  return all_returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUGFjjMy7hR5"
      },
      "outputs": [],
      "source": [
        "# Create the environment.\n",
        "#environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v0'))\n",
        "environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v1'))\n",
        "environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "\n",
        "# Get the environment's specification.\n",
        "environment_spec = acme.specs.make_environment_spec(environment)\n",
        "\n",
        "# Build the agent's network.\n",
        "q_network = snt.Sequential([\n",
        "    snt.Flatten(),\n",
        "    snt.nets.MLP([100, environment_spec.actions.num_values])\n",
        "])\n",
        "\n",
        "learning_rate = 1e-3 \n",
        "\n",
        "# Create the agent.\n",
        "agent = dqn.DQN(\n",
        "    environment_spec=environment_spec,\n",
        "    network=q_network,\n",
        "    batch_size=64,\n",
        "    epsilon=epsilon,\n",
        "    learning_rate=learning_rate,\n",
        "    min_replay_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iSgDpU_bGts"
      },
      "outputs": [],
      "source": [
        "acme.specs.make_environment_spec(environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8psppdCzq9bT"
      },
      "outputs": [],
      "source": [
        "query_environment('CartPole-v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlBQfJ1iuKUy"
      },
      "outputs": [],
      "source": [
        "#@title Construct the agent and run the training loop { form-width: \"30%\" }\n",
        "\n",
        "\n",
        "num_episodes = 500  # @param {type: \"number\"}\n",
        "epsilon = 0.1  # @param {type: \"number\"}\n",
        "learning_rate = 1e-3  # @param {type: \"number\"}\n",
        "\n",
        "# Create the environment.\n",
        "#environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v0'))\n",
        "environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v1'))\n",
        "environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "\n",
        "# Get the environment's specification.\n",
        "environment_spec = acme.specs.make_environment_spec(environment)\n",
        "\n",
        "# Build the agent's network.\n",
        "q_network = snt.Sequential([\n",
        "    snt.Flatten(),\n",
        "    snt.nets.MLP([100, environment_spec.actions.num_values])\n",
        "])\n",
        "\n",
        "# Create the agent.\n",
        "agent = dqn.DQN(\n",
        "    environment_spec=environment_spec,\n",
        "    network=q_network,\n",
        "    batch_size=64,\n",
        "    epsilon=epsilon,\n",
        "    learning_rate=learning_rate,\n",
        "    min_replay_size=100)\n",
        "\n",
        "# Train the agent.\n",
        "returns = run_loop(environment=environment, agent=agent, num_episodes=num_episodes, \n",
        "         logger_time_delta=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_awhs7RAV3V"
      },
      "outputs": [],
      "source": [
        "#@title Visualise the training curve { form-width: \"30%\" }\n",
        "\n",
        "# Compute rolling average over returns\n",
        "returns_avg = pd.Series(returns).rolling(10, center=True).mean()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(len(returns)), returns_avg)\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Episode return');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-E6I20ktjEY"
      },
      "outputs": [],
      "source": [
        "frame = environment.environment.render(mode='rgb_array')\n",
        "plt.imshow(frame)\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZvtKa3PlziR"
      },
      "outputs": [],
      "source": [
        "def display_video(frames, filename='temp.mp4'):\n",
        "  \"\"\"Save and display video.\"\"\"\n",
        "  # Write video\n",
        "  with imageio.get_writer(filename, fps=60) as video:\n",
        "    for frame in frames:\n",
        "      video.append_data(frame)\n",
        "  # Read video and display the video\n",
        "  video = open(filename, 'rb').read()\n",
        "  b64_video = base64.b64encode(video)\n",
        "  video_tag = ('<video  width=\"320\" height=\"240\" controls alt=\"test\" '\n",
        "               'src=\"data:video/mp4;base64,{0}\">').format(b64_video.decode())\n",
        "  return IPython.display.HTML(video_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_pTzHZARf3M"
      },
      "outputs": [],
      "source": [
        "# Create the environment.\n",
        "environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v1'))\n",
        "environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "\n",
        "\n",
        "# Run the actor in the environment for desired number of steps.\n",
        "frames = []\n",
        "#num_steps = 500\n",
        "num_steps = 1000\n",
        "timestep = environment.reset()\n",
        "reward_history = []\n",
        "error_history = []\n",
        "discount_history = []\n",
        "\n",
        "for _ in range(num_steps):\n",
        "  frame = environment.environment.render(mode='rgb_array')\n",
        "  frames.append(frame)\n",
        "  action = agent.select_action(timestep.observation)\n",
        "  timestep = environment.step(action)\n",
        "  reward_history.append(timestep.reward)\n",
        "  error_history.append(timestep.observation[2])\n",
        "  discount_history.append(timestep.discount)\n",
        "\n",
        "# Save video of the behaviour.\n",
        "display_video(np.array(frames))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqGslnvTHgCy"
      },
      "outputs": [],
      "source": [
        "plt.plot(reward_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP-rbxahIXUw"
      },
      "outputs": [],
      "source": [
        "plt.plot(error_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wIHiYqYvriW"
      },
      "outputs": [],
      "source": [
        "plt.plot(discount_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8A9KK-DwdCc"
      },
      "outputs": [],
      "source": [
        "discount_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QxiRYTRLBGJ"
      },
      "outputs": [],
      "source": [
        "# Create the environment.\n",
        "environment = wrappers.gym_wrapper.GymWrapper(gym.make('CartPole-v1'))\n",
        "environment = wrappers.SinglePrecisionWrapper(environment)\n",
        "\n",
        "\n",
        "# Run the actor in the environment for desired number of steps.\n",
        "frames = []\n",
        "#num_steps = 500\n",
        "num_steps = 1000\n",
        "timestep = environment.reset()\n",
        "reward_history = []\n",
        "error_history = []\n",
        "\n",
        "integral = 0\n",
        "derivative = 0\n",
        "prev_error = 0\n",
        "#pid_history = []\n",
        "#state_history = []\n",
        "#masked_state_history = []\n",
        "#action_history = []\n",
        "#masked_pid_history = []\n",
        "\n",
        "\n",
        "P, I, D = 0.02, 0.01, 0.5\n",
        "\n",
        "\n",
        "for _ in range(num_steps):\n",
        "  frame = environment.environment.render(mode='rgb_array')\n",
        "  frames.append(frame)\n",
        "  error = timestep.observation[2]  # Why is it so simple?\n",
        "  error_history.append(error)\n",
        "  integral += error\n",
        "  derivative = error - prev_error\n",
        "  prev_error = error\n",
        "  pid = P * error + I * integral + D * derivative\n",
        "  action = sigmoid(pid)\n",
        "  action = np.round(action).astype(np.int32)\n",
        "  timestep = environment.step(action)\n",
        "  reward_history.append(timestep.reward)\n",
        "\n",
        "# Save video of the behaviour.\n",
        "display_video(np.array(frames))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eJaXyrAKhAD"
      },
      "outputs": [],
      "source": [
        "plt.plot(error_history)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_gnRU_3Bb03"
      },
      "outputs": [],
      "source": [
        "!pip freeze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxzpGC6iFpPv"
      },
      "source": [
        "A working set of packages: \n",
        "absl-py==1.0.0\n",
        "alabaster==0.7.12\n",
        "albumentations==0.1.12\n",
        "ale-py==0.7.3\n",
        "altair==4.2.0\n",
        "appdirs==1.4.4\n",
        "argon2-cffi==21.3.0\n",
        "argon2-cffi-bindings==21.2.0\n",
        "arviz==0.11.4\n",
        "astor==0.8.1\n",
        "astropy==4.3.1\n",
        "astunparse==1.6.3\n",
        "atari-py==0.2.9\n",
        "atomicwrites==1.4.0\n",
        "attrs==21.4.0\n",
        "audioread==2.1.9\n",
        "autograd==1.3\n",
        "AutoROM==0.4.2\n",
        "AutoROM.accept-rom-license==0.4.2\n",
        "Babel==2.9.1\n",
        "backcall==0.2.0\n",
        "beautifulsoup4==4.6.3\n",
        "bleach==4.1.0\n",
        "blis==0.4.1\n",
        "bokeh==2.3.3\n",
        "Bottleneck==1.3.2\n",
        "box2d-py==2.3.5\n",
        "branca==0.4.2\n",
        "bs4==0.0.1\n",
        "bsuite==0.3.5\n",
        "CacheControl==0.12.10\n",
        "cached-property==1.5.2\n",
        "cachetools==4.2.4\n",
        "catalogue==1.0.0\n",
        "certifi==2021.10.8\n",
        "cffi==1.15.0\n",
        "cftime==1.5.2\n",
        "chardet==3.0.4\n",
        "charset-normalizer==2.0.11\n",
        "click==7.1.2\n",
        "cloudpickle==1.3.0\n",
        "cmake==3.12.0\n",
        "cmdstanpy==0.9.5\n",
        "colorcet==3.0.0\n",
        "colorlover==0.3.0\n",
        "community==1.0.0b1\n",
        "contextlib2==0.5.5\n",
        "convertdate==2.4.0\n",
        "coverage==3.7.1\n",
        "coveralls==0.5\n",
        "crcmod==1.7\n",
        "cufflinks==0.17.3\n",
        "cvxopt==1.2.7\n",
        "cvxpy==1.0.31\n",
        "cycler==0.11.0\n",
        "cymem==2.0.6\n",
        "Cython==0.29.27\n",
        "daft==0.0.4\n",
        "dask==2.12.0\n",
        "datascience==0.10.6\n",
        "debugpy==1.0.0\n",
        "decorator==4.4.2\n",
        "defusedxml==0.7.1\n",
        "descartes==1.1.0\n",
        "dill==0.3.4\n",
        "distributed==1.25.3\n",
        "dlib @ file:///dlib-19.18.0-cp37-cp37m-linux_x86_64.whl\n",
        "dm-acme==0.3.0\n",
        "dm-control==0.0.364896371\n",
        "dm-env==1.5\n",
        "dm-launchpad==0.4.1\n",
        "dm-reverb==0.6.1\n",
        "dm-sonnet==2.0.0\n",
        "dm-tree==0.1.6\n",
        "docopt==0.6.2\n",
        "docutils==0.17.1\n",
        "dopamine-rl==1.0.5\n",
        "earthengine-api==0.1.297\n",
        "easydict==1.9\n",
        "ecos==2.0.10\n",
        "editdistance==0.5.3\n",
        "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\n",
        "entrypoints==0.4\n",
        "ephem==4.1.3\n",
        "et-xmlfile==1.1.0\n",
        "ez-setup==0.9\n",
        "fa2==0.3.5\n",
        "fastai==1.0.61\n",
        "fastdtw==0.3.4\n",
        "fastprogress==1.0.0\n",
        "fastrlock==0.8\n",
        "fbprophet==0.7.1\n",
        "feather-format==0.4.1\n",
        "filelock==3.4.2\n",
        "firebase-admin==4.4.0\n",
        "fix-yahoo-finance==0.0.22\n",
        "Flask==1.1.4\n",
        "flatbuffers==2.0\n",
        "folium==0.8.3\n",
        "frozendict==2.3.0\n",
        "future==0.16.0\n",
        "gast==0.4.0\n",
        "GDAL==2.2.2\n",
        "gdown==4.2.1\n",
        "gensim==3.6.0\n",
        "geographiclib==1.52\n",
        "geopy==1.17.0\n",
        "gin-config==0.5.0\n",
        "glfw==2.5.0\n",
        "glob2==0.7\n",
        "google==2.0.3\n",
        "google-api-core==1.26.3\n",
        "google-api-python-client==1.12.10\n",
        "google-auth==1.35.0\n",
        "google-auth-httplib2==0.0.4\n",
        "google-auth-oauthlib==0.4.6\n",
        "google-cloud-bigquery==1.21.0\n",
        "google-cloud-bigquery-storage==1.1.0\n",
        "google-cloud-core==1.0.3\n",
        "google-cloud-datastore==1.8.0\n",
        "google-cloud-firestore==1.7.0\n",
        "google-cloud-language==1.2.0\n",
        "google-cloud-storage==1.18.1\n",
        "google-cloud-translate==1.5.0\n",
        "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n",
        "google-pasta==0.2.0\n",
        "google-resumable-media==0.4.1\n",
        "googleapis-common-protos==1.54.0\n",
        "googledrivedownloader==0.4\n",
        "graphviz==0.10.1\n",
        "greenlet==1.1.2\n",
        "grpcio==1.43.0\n",
        "gspread==3.4.2\n",
        "gspread-dataframe==3.0.8\n",
        "gym==0.21.0\n",
        "h5py==3.1.0\n",
        "HeapDict==1.0.1\n",
        "hijri-converter==2.2.2\n",
        "holidays==0.10.5.2\n",
        "holoviews==1.14.7\n",
        "html5lib==1.0.1\n",
        "httpimport==0.5.18\n",
        "httplib2==0.17.4\n",
        "httplib2shim==0.0.3\n",
        "humanize==0.5.1\n",
        "hyperopt==0.1.2\n",
        "ideep4py==2.0.0.post3\n",
        "idna==2.10\n",
        "imageio==2.4.0\n",
        "imagesize==1.3.0\n",
        "imbalanced-learn==0.8.1\n",
        "imblearn==0.0\n",
        "imgaug==0.2.9\n",
        "importlib-metadata==4.10.1\n",
        "importlib-resources==5.4.0\n",
        "imutils==0.5.4\n",
        "inflect==2.1.0\n",
        "iniconfig==1.1.1\n",
        "intel-openmp==2022.0.2\n",
        "intervaltree==2.1.0\n",
        "ipykernel==4.10.1\n",
        "ipython==5.5.0\n",
        "ipython-genutils==0.2.0\n",
        "ipython-sql==0.3.9\n",
        "ipywidgets==7.6.5\n",
        "itsdangerous==1.1.0\n",
        "jax==0.2.25\n",
        "jaxlib @ https://storage.googleapis.com/jax-releases/cuda111/jaxlib-0.1.71+cuda111-cp37-none-manylinux2010_x86_64.whl\n",
        "jedi==0.18.1\n",
        "jieba==0.42.1\n",
        "Jinja2==2.11.3\n",
        "joblib==1.1.0\n",
        "jpeg4py==0.1.4\n",
        "jsonschema==4.3.3\n",
        "jupyter==1.0.0\n",
        "jupyter-client==5.3.5\n",
        "jupyter-console==5.2.0\n",
        "jupyter-core==4.9.1\n",
        "jupyterlab-pygments==0.1.2\n",
        "jupyterlab-widgets==1.0.2\n",
        "kaggle==1.5.12\n",
        "kapre==0.3.7\n",
        "keras==2.7.0\n",
        "Keras-Preprocessing==1.1.2\n",
        "keras-vis==0.4.1\n",
        "kiwisolver==1.3.2\n",
        "korean-lunar-calendar==0.2.1\n",
        "labmaze==1.0.5\n",
        "libclang==13.0.0\n",
        "librosa==0.8.1\n",
        "lightgbm==2.2.3\n",
        "llvmlite==0.34.0\n",
        "lmdb==0.99\n",
        "LunarCalendar==0.0.9\n",
        "lxml==4.2.6\n",
        "Markdown==3.3.6\n",
        "MarkupSafe==2.0.1\n",
        "matplotlib==3.2.2\n",
        "matplotlib-inline==0.1.3\n",
        "matplotlib-venn==0.11.6\n",
        "missingno==0.5.0\n",
        "mistune==0.8.4\n",
        "mizani==0.6.0\n",
        "mkl==2019.0\n",
        "mlxtend==0.14.0\n",
        "mock==4.0.3\n",
        "more-itertools==8.12.0\n",
        "moviepy==0.2.3.5\n",
        "mpmath==1.2.1\n",
        "msgpack==1.0.3\n",
        "multiprocess==0.70.12.2\n",
        "multitasking==0.0.10\n",
        "murmurhash==1.0.6\n",
        "music21==5.5.0\n",
        "natsort==5.5.0\n",
        "nbclient==0.5.10\n",
        "nbconvert==5.6.1\n",
        "nbformat==5.1.3\n",
        "nest-asyncio==1.5.4\n",
        "netCDF4==1.5.8\n",
        "networkx==2.6.3\n",
        "nibabel==3.0.2\n",
        "nltk==3.2.5\n",
        "notebook==5.3.1\n",
        "numba==0.51.2\n",
        "numexpr==2.8.1\n",
        "numpy==1.21.5\n",
        "nvidia-ml-py3==7.352.0\n",
        "oauth2client==4.1.3\n",
        "oauthlib==3.2.0\n",
        "okgrade==0.4.3\n",
        "opencv-contrib-python==4.1.2.30\n",
        "opencv-python==4.1.2.30\n",
        "openpyxl==3.0.9\n",
        "opt-einsum==3.3.0\n",
        "osqp==0.6.2.post0\n",
        "packaging==21.3\n",
        "palettable==3.3.0\n",
        "pandas==1.3.5\n",
        "pandas-datareader==0.9.0\n",
        "pandas-gbq==0.13.3\n",
        "pandas-profiling==1.4.1\n",
        "pandocfilters==1.5.0\n",
        "panel==0.12.1\n",
        "param==1.12.0\n",
        "parso==0.8.3\n",
        "pathlib==1.0.1\n",
        "patsy==0.5.2\n",
        "pep517==0.12.0\n",
        "pexpect==4.8.0\n",
        "pickleshare==0.7.5\n",
        "piglet==1.0.0\n",
        "piglet-templates==1.2.0\n",
        "Pillow==7.1.2\n",
        "pip-tools==6.2.0\n",
        "plac==1.1.3\n",
        "plotly==5.5.0\n",
        "plotnine==0.6.0\n",
        "pluggy==0.7.1\n",
        "pooch==1.6.0\n",
        "portpicker==1.3.9\n",
        "prefetch-generator==1.0.1\n",
        "preshed==3.0.6\n",
        "prettytable==3.0.0\n",
        "progressbar2==3.38.0\n",
        "prometheus-client==0.13.1\n",
        "promise==2.3\n",
        "prompt-toolkit==1.0.18\n",
        "protobuf==3.17.3\n",
        "psutil==5.4.8\n",
        "psycopg2==2.7.6.1\n",
        "ptyprocess==0.7.0\n",
        "py==1.11.0\n",
        "pyarrow==6.0.1\n",
        "pyasn1==0.4.8\n",
        "pyasn1-modules==0.2.8\n",
        "pycocotools==2.0.4\n",
        "pycparser==2.21\n",
        "pyct==0.4.8\n",
        "pydata-google-auth==1.3.0\n",
        "pydot==1.3.0\n",
        "pydot-ng==2.0.0\n",
        "pydotplus==2.0.2\n",
        "PyDrive==1.3.1\n",
        "pyemd==0.5.1\n",
        "pyerfa==2.0.0.1\n",
        "pyglet==1.5.0\n",
        "Pygments==2.6.1\n",
        "PyGObject==3.26.1\n",
        "pymc3==3.11.4\n",
        "PyMeeus==0.5.11\n",
        "pymongo==4.0.1\n",
        "pymystem3==0.2.0\n",
        "PyOpenGL==3.1.5\n",
        "pyparsing==3.0.7\n",
        "pyrsistent==0.18.1\n",
        "pysndfile==1.3.8\n",
        "PySocks==1.7.1\n",
        "pystan==2.19.1.1\n",
        "pytest==3.6.4\n",
        "python-apt==0.0.0\n",
        "python-chess==0.23.11\n",
        "python-dateutil==2.8.2\n",
        "python-louvain==0.16\n",
        "python-slugify==5.0.2\n",
        "python-utils==3.1.0\n",
        "pytz==2018.9\n",
        "PyVirtualDisplay==3.0\n",
        "pyviz-comms==2.1.0\n",
        "PyWavelets==1.2.0\n",
        "PyYAML==3.13\n",
        "pyzmq==22.3.0\n",
        "qdldl==0.1.5.post0\n",
        "qtconsole==5.2.2\n",
        "QtPy==2.0.1\n",
        "regex==2019.12.20\n",
        "requests==2.23.0\n",
        "requests-oauthlib==1.3.1\n",
        "resampy==0.2.2\n",
        "rpy2==3.4.5\n",
        "rsa==4.8\n",
        "scikit-image==0.18.3\n",
        "scikit-learn==1.0.2\n",
        "scipy==1.4.1\n",
        "screen-resolution-extra==0.0.0\n",
        "scs==3.1.0\n",
        "seaborn==0.11.2\n",
        "semver==2.13.0\n",
        "Send2Trash==1.8.0\n",
        "setuptools-git==1.2\n",
        "Shapely==1.8.0\n",
        "simplegeneric==0.8.1\n",
        "six==1.15.0\n",
        "sklearn==0.0\n",
        "sklearn-pandas==1.8.0\n",
        "smart-open==5.2.1\n",
        "snowballstemmer==2.2.0\n",
        "sortedcontainers==2.4.0\n",
        "SoundFile==0.10.3.post1\n",
        "spacy==2.2.4\n",
        "Sphinx==1.8.6\n",
        "sphinxcontrib-serializinghtml==1.1.5\n",
        "sphinxcontrib-websupport==1.2.4\n",
        "SQLAlchemy==1.4.31\n",
        "sqlparse==0.4.2\n",
        "srsly==1.0.5\n",
        "statsmodels==0.10.2\n",
        "sympy==1.7.1\n",
        "tables==3.7.0\n",
        "tabulate==0.8.9\n",
        "tblib==1.7.0\n",
        "tenacity==8.0.1\n",
        "tensorboard==2.7.0\n",
        "tensorboard-data-server==0.6.1\n",
        "tensorboard-plugin-wit==1.8.1\n",
        "tensorflow @ file:///tensorflow-2.7.0-cp37-cp37m-linux_x86_64.whl\n",
        "tensorflow-datasets==4.4.0\n",
        "tensorflow-estimator==2.7.0\n",
        "tensorflow-gcs-config==2.7.0\n",
        "tensorflow-hub==0.12.0\n",
        "tensorflow-io-gcs-filesystem==0.24.0\n",
        "tensorflow-metadata==1.6.0\n",
        "tensorflow-probability==0.15.0\n",
        "termcolor==1.1.0\n",
        "terminado==0.13.1\n",
        "testpath==0.5.0\n",
        "text-unidecode==1.3\n",
        "textblob==0.15.3\n",
        "tf-agents==0.11.0\n",
        "Theano-PyMC==1.1.2\n",
        "thinc==7.4.0\n",
        "threadpoolctl==3.1.0\n",
        "tifffile==2021.11.2\n",
        "tomli==2.0.0\n",
        "toolz==0.11.2\n",
        "torch @ https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "torchaudio @ https://download.pytorch.org/whl/cu111/torchaudio-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "torchsummary==1.5.1\n",
        "torchtext==0.11.0\n",
        "torchvision @ https://download.pytorch.org/whl/cu111/torchvision-0.11.1%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "tornado==5.1.1\n",
        "tqdm==4.62.3\n",
        "traitlets==5.1.1\n",
        "trfl==1.2.0\n",
        "tweepy==3.10.0\n",
        "typeguard==2.7.1\n",
        "typing-extensions==3.10.0.2\n",
        "tzlocal==1.5.1\n",
        "uritemplate==3.0.1\n",
        "urllib3==1.24.3\n",
        "vega-datasets==0.9.0\n",
        "wasabi==0.9.0\n",
        "wcwidth==0.2.5\n",
        "webencodings==0.5.1\n",
        "Werkzeug==1.0.1\n",
        "widgetsnbextension==3.5.2\n",
        "wordcloud==1.5.0\n",
        "wrapt==1.13.3\n",
        "xarray==0.18.2\n",
        "xgboost==0.90\n",
        "xkit==0.0.0\n",
        "xlrd==1.1.0\n",
        "xlwt==1.3.0\n",
        "yellowbrick==1.3.post1\n",
        "zict==2.0.0\n",
        "zipp==3.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t2vjSaUF1ka"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}